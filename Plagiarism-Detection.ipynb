{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cNSUNEq4tBOi",
        "outputId": "fbc95148-dc26-4b26-d557-b1c41cfedeff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spark-3.4.1-bin-hadoop3/\n",
            "spark-3.4.1-bin-hadoop3/R/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/sparkr.zip\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.4.1-bin-hadoop3/sbin/\n",
            "spark-3.4.1-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-connect-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-connect-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.4.1-bin-hadoop3/python/\n",
            "spark-3.4.1-bin-hadoop3/python/dist/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/test_pytorch_training_file.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.4.1-bin-hadoop3/python/setup.cfg\n",
            "spark-3.4.1-bin-hadoop3/python/run-tests.py\n",
            "spark-3.4.1-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.4.1-bin-hadoop3/python/docs/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/udf.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/protobuf.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/resampling.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.errors.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_upgrade.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_connect.ipynb\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
            "spark-3.4.1-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.4.1-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.4.1-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.4.1-bin-hadoop3/python/README.md\n",
            "spark-3.4.1-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.4.1-bin-hadoop3/python/.gitignore\n",
            "spark-3.4.1-bin-hadoop3/python/.coveragerc\n",
            "spark-3.4.1-bin-hadoop3/python/mypy.ini\n",
            "spark-3.4.1-bin-hadoop3/python/setup.py\n",
            "spark-3.4.1-bin-hadoop3/python/run-tests\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/distributor.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/torch_run_process_wrapper.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_log_communication.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_distributor.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/log_communication.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_model_cache.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/model_cache.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/test_errors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/connect.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/error_classes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_stage_sched.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rddsampler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_memory_profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/connectutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_scalars.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_resample.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_slow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby_slow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_generic_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ewm.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_slow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/resample.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/scalars.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/resample.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/correlation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/supported_api_gen.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_sqlmetrics.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_errors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_scalar.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_grouped_agg.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_serde.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_errors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_datasources.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_cogrouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_plan.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_function.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_basic.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_client.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_python_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/state.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/query.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2_grpc.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/session.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/plan.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/expressions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/client.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/_typing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.4.1-bin-hadoop3/python/lib/\n",
            "spark-3.4.1-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.4.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip\n",
            "spark-3.4.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.4.1-bin-hadoop3/bin/\n",
            "spark-3.4.1-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/sparkR\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-submit\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-sql\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-shell\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-connect-shell\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-class\n",
            "spark-3.4.1-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/run-example\n",
            "spark-3.4.1-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/pyspark\n",
            "spark-3.4.1-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.4.1-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/find-spark-home\n",
            "spark-3.4.1-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.4.1-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/beeline\n",
            "spark-3.4.1-bin-hadoop3/README.md\n",
            "spark-3.4.1-bin-hadoop3/conf/\n",
            "spark-3.4.1-bin-hadoop3/conf/workers.template\n",
            "spark-3.4.1-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.4.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.4.1-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.4.1-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.4.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.4.1-bin-hadoop3/data/\n",
            "spark-3.4.1-bin-hadoop3/data/streaming/\n",
            "spark-3.4.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/als/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.4.1-bin-hadoop3/data/graphx/\n",
            "spark-3.4.1-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.4.1-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.4.1-bin-hadoop3/NOTICE\n",
            "spark-3.4.1-bin-hadoop3/licenses/\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.4.1-bin-hadoop3/LICENSE\n",
            "spark-3.4.1-bin-hadoop3/examples/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.4.1-bin-hadoop3/examples/jars/\n",
            "spark-3.4.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.4.1-bin-hadoop3/yarn/\n",
            "spark-3.4.1-bin-hadoop3/yarn/spark-3.4.1-yarn-shuffle.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/\n",
            "spark-3.4.1-bin-hadoop3/jars/rocksdbjni-7.9.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/py4j-0.10.9.7.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/pickle-1.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-jackson-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-hadoop-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-format-structures-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-encoding-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-common-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-column-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/orc-shims-1.8.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/orc-mapreduce-1.8.4-shaded-protobuf.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/orc-core-1.8.4-shaded-protobuf.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/okio-1.15.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/objenesis-3.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.87.Final-osx-x86_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.87.Final-osx-aarch_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.87.Final-linux-x86_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.87.Final-linux-aarch_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-resolver-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-handler-proxy-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-handler-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-common-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-socks-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-http2-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-http-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-buffer-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-all-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-jvm-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-json-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-jmx-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-graphite-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-core-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-slf4j2-impl-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-core-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-api-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-1.2-api-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/lapack-3.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-storageclass-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-scheduling-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-rbac-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-policy-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-node-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-networking-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-metrics-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-gatewayapi-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-extensions-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-events-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-discovery-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-core-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-coordination-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-common-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-certificates-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-batch-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-autoscaling-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-apps-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-apiextensions-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-httpclient-okhttp-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-client-api-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-client-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jul-to-slf4j-2.0.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/joda-time-2.12.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-server-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-hk2-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-container-servlet-core-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-container-servlet-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-common-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-client-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jcl-over-slf4j-2.0.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/janino-3.1.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-databind-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-core-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-annotations-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/ivy-2.5.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/httpcore-4.4.16.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/httpclient-4.5.14.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-storage-api-2.8.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-service-rpc-3.1.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-client-api-3.3.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/compress-lzf-1.1.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-text-1.10.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-io-2.11.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-compress-1.22.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-compiler-3.1.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-codec-1.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/breeze_2.12-2.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/breeze-macros_2.12-2.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/blas-3.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/avro-mapred-1.11.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/avro-ipc-1.11.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/avro-1.11.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-vector-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-memory-netty-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-memory-core-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-format-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arpack-3.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/antlr4-runtime-4.9.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/aircompressor-0.21.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/RoaringBitmap-0.9.38.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zstd-jni-1.5.2-5.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zookeeper-jute-3.6.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zookeeper-3.6.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/xz-1.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/xbean-asm9-shaded-4.22.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/tink-1.7.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/threeten-extra-1.7.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-yarn_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-unsafe_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-tags_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-streaming_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-sql_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-sketch_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-repl_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-network-common_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-mllib_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-mesos_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-launcher_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-kvstore_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-hive_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-graphx_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-core_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-catalyst_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/snappy-java-1.1.10.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/snakeyaml-1.33.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/slf4j-api-2.0.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/shims-0.9.38.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-xml_2.12-2.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-reflect-2.12.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-parser-combinators_2.12-2.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-library-2.12.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-compiler-2.12.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.7.0.jar\n",
            "spark-3.4.1-bin-hadoop3/RELEASE\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m635.7/635.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a41838d431c7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ec6617f7410>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Install Java\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Extract Spark\n",
        "!tar -xvzf spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Install Spark NLP and findspark\n",
        "!pip install -q findspark spark-nlp\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#  Start Spark NLP session (IMPORTANT!)\n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Obm9Wlzhu1JZ",
        "outputId": "de4a6614-6fa4-4ab2-cf83-3328da66ff6b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a41838d431c7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ec6617f7410>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "R-jEheFbvZbY",
        "outputId": "efb03c5e-aa6a-4886-8ccc-980f73bbbc83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89fa7b99-737c-454a-a5ab-087cede00b41\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89fa7b99-737c-454a-a5ab-087cede00b41\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving user_input.txt to user_input.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukd0LPIywAJ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = '/content/user_input.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHurvfRUwGrY",
        "outputId": "2e426882-ceba-44c5-e347-cc21dce877a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------+\n",
            "|## **Functional Requirements**  |\n",
            "+--------------------------------+\n",
            "|            ### **1. Authenti...|\n",
            "|             **Objective:** ...|\n",
            "|             **Functionaliti...|\n",
            "|            - Test weak passw...|\n",
            "|            - Detect **insecu...|\n",
            "+--------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df = spark.read.csv('/content/user_input.txt', header=True, inferSchema=True)\n",
        "df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPmIpDpnwOFJ",
        "outputId": "131309e0-bf3c-45cf-ca0e-b8486b40572a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.5\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX27g9A6wSKg",
        "outputId": "638de68a-520f-4bcd-d6cc-7301b26e06c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## **Functional Requirements**  \n",
            "### **1. Authentication Handling & Session\n",
            "Management**  \n",
            " **Objective:** Identify weak authentication\n",
            "mechanisms, insecure session handling, and credential\n",
            "exposure.  \n",
            " **Functionalities:**  \n",
            "- Test weak passwords via **dictionary attacks**\n",
            "(`requests`, `bcrypt`).  \n",
            "- Detect **insecure authentication mechanisms**\n",
            "(e.g., Basic Auth, JWT flaws).  \n",
            "- Check for **session fixation & session hijacking**\n",
            "vulnerabilities.  \n",
            "- Analyze **cookies for missing security fla\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "pdf_file_path = '/content/user_input.txt'\n",
        "pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "\n",
        "pdf_text = \"\"\n",
        "for page_num in range(pdf_document.page_count):\n",
        "    page = pdf_document.load_page(page_num)\n",
        "    pdf_text += page.get_text()\n",
        "\n",
        "\n",
        "print(pdf_text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLqRz8R6wfC4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PlagiarismDetection\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoXE5EgSwnkB",
        "outputId": "fcdfadaa-7a80-4d0a-8dab-93207f635127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|## **Functional Requirements**  \\n### **1. Authentication Handling & Session\\nManagement**  \\n **Objective:** Identify weak authentication\\nmechanisms, insecure session handling, and credential\\nexposure.  \\n **Functionalities:**  \\n- Test weak passwords via **dictionary attacks**\\n(`requests`, `bcrypt`).  \\n- Detect **insecure authentication mechanisms**\\n(e.g., Basic Auth, JWT flaws).  \\n- Check for **session fixation & session hijacking**\\nvulnerabilities.  \\n- Analyze **cookies for missing security flags**\\n(HttpOnly, Secure, SameSite).  \\n- Validate **password reset mechanisms** for\\npredictable tokens.  \\n **OOP Design:**  \\n- **Class:** `AuthenticationTester`  \\n- **Encapsulation:** Handles cookie/token storage\\nsecurely.  \\n- **Inheritance:** Supports different authentication\\ntypes (Basic, Form-based, OAuth).  \\n- **Polymorphism:** Implements various attack vectors\\n(brute-force, token tampering).  \\n **Technologies:**  \\n- **Python Libraries:** `requests`, `selenium`,\\n`jwt`, `bcrypt`.  \\n- **External Tools:** Hydra (for brute-force login\\nattempts).  \\n---\\n### **2. SSL/TLS Vulnerability Scanner**  \\n **Objective:** Detect outdated encryption\\nprotocols, weak ciphers, and certificate\\nmisconfigurations.  \\n **Functionalities:**  \\n- Check for **expired/misconfigured SSL\\ncertificates**.  \\n- Identify **weak TLS versions** (e.g., TLS 1.0, SSL\\n3.0).  \\n- Verify **HTTP Strict Transport Security (HSTS)\\nimplementation**.  \\n- Analyze **certificate chain and trust issues**.  \\n **OOP Design:**  \\n- **Class:** `SSLScanner`  \\n- **Encapsulation:** Stores SSL analysis logic\\nseparately.  \\n- **Polymorphism:** Supports different scanning\\napproaches (OpenSSL, nmap scripts).  \\n **Technologies:**  \\n- **Python Libraries:** `sslyze`, `requests`.  \\n- **External Tools:** `nmap --script ssl-*`,\\n`openssl`.  \\n---\\n### **3. File and Directory Discovery**  \\n **Objective:** Locate hidden or sensitive files\\nthat might expose security risks.  \\n **Functionalities:**  \\n- Enumerate **hidden directories (`.git/`,\\n`backup.zip`)**.  \\n- Detect **sensitive files (`config.php`, `.env`,\\n`database.sql`)**.  \\n- Brute-force **directory paths using wordlists**\\n(`dirsearch`).  \\n- Identify **exposed backups/log files**\\n(`access.log`, `debug.log`).  \\n- Check for **default web application files** (admin\\npanels, API docs).  \\n **OOP Design:**  \\n- **Class:** `DirScanner`  \\n- **Encapsulation:** Manages wordlist processing and\\nresponse parsing.  \\n- **Composition:** Integrates `dirsearch` and `ffuf`\\nfor brute-force scanning.  \\n **Technologies:**  \\n- **Python Libraries:** `requests`, `BeautifulSoup`. \\n- **External Tools:** `dirsearch`, `wfuzz`, `ffuf`.  \\n---\\n### **4. API Scanning**  \\n **Objective:** Identify security flaws in web\\nAPIs, such as improper authentication, excessive data\\nexposure, and rate-limiting issues.  \\n **Functionalities:**  \\n- Discover **exposed API endpoints (OpenAPI,\\nGraphQL)**.  \\n- Identify **API rate-limiting issues** via request\\nflooding.  \\n- Test for **IDOR (Insecure Direct Object\\nReferences)**.  \\n- Analyze **improper authentication/token management\\n(OAuth, JWT)**.  \\n **OOP Design:**  \\n- **Class:** `APIScanner`  \\n- **Inheritance:** Supports multiple API types (REST,\\nSOAP, GraphQL).  \\n- **Encapsulation:** Separates authentication\\nhandling, request generation, and response\\nvalidation.  \\n **Technologies:**  \\n- **Python Libraries:** `requests`, `jwt`,\\n`BeautifulSoup`.  \\n- **External Tools:** `nmap -sV --script http-*`,\\n`Postman API`.  \\n---\\n### **5. Port Scanning**  \\n **Objective:** Identify open ports, running\\nservices, and potential vulnerabilities.  \\n **Functionalities:**  \\n- Scan **open ports** and identify running services. \\n- Perform **TCP & UDP scanning**.  \\n- Detect **firewall and intrusion prevention\\nmechanisms**.  \\n **OOP Design:**  \\n- **Class:** `PortScanner`  \\n- **Encapsulation:** Stores scanning logic\\nseparately.  \\n- **Polymorphism:** Implements different scanning\\ntypes (SYN, full-connect, UDP).  \\n **Technologies:**  \\n- **Python Libraries:** `socket`, `scapy`.  \\n- **External Tools:** `nmap`, `masscan`.  \\n---\\n## **6. Reporting & Logging**  \\n **Objective:** Generate reports, categorize\\nvulnerabilities, and maintain logs for auditing.  \\n **Functionalities:**  \\n- Generate structured reports (`JSON`, `CSV`, `TXT`).\\n \\n- Categorize vulnerabilities (Critical, High, Medium,\\nLow).  \\n- Format output using **rich text CLI (tables,\\ncolors)**.  \\n- Maintain **detailed logs for security auditing**.  \\n **OOP Design:**  \\n- **Class:** `ReportGenerator`  \\n- **Encapsulation:** Manages data storage separately.\\n \\n- **Composition:** Integrates vulnerability scanners\\nfor aggregated reporting.  \\n **Technologies:**  \\n- **Python Libraries:** `pandas`, `json`, `rich`.  \\n---\\n## **CLI Design & Usage**  \\n```bash\\n# Example commands\\npython3 pentest_tool.py --auth-check <target_url>\\npython3 pentest_tool.py --ssl-scan <target_url>\\npython3 pentest_tool.py --dir-scan <target_url> --\\nwordlist common.txt\\npython3 pentest_tool.py --api-scan <target_url>\\npython3 pentest_tool.py --port-scan <target_ip>\\npython3 pentest_tool.py --report output.json\\n```\\n---\\n## **OOP Benefits in the Project**\\n **Encapsulation:** Each feature is modular, making\\nthe code **organized and maintainable**.  \\n **Inheritance:** Common tasks like sending HTTP\\nrequests are **reused across modules**.  \\n **Polymorphism:** The tool can **handle multiple\\ntypes of scans/vulnerabilities** seamlessly.  \\n **Abstraction:** Users **interact with simple CLI\\ncommands**, while the tool handles complexity in the\\nbackground.  \\n---\\n## **Future Enhancements**  \\n **Multi-threading for faster scanning**\\n(`concurrent.futures`, `asyncio`).  \\n **GUI-based version for easier usage** (`PyQt` or\\n`Tkinter`).  \\n **Machine Learning module for vulnerability\\ndetection patterns**.  \\n---\\n## **Why This Matters**\\nThis tool simplifies web security **by automating\\npenetration testing**, reducing manual effort for\\nsecurity teams. Whether you're a **developer,\\nsecurity researcher, or ethical hacker**, it provides\\na **powerful yet easy-to-use solution** for web\\napplication security.\\n---\\n **Next Steps: Do you want me to generate a basic\\nPython class structure to kickstart development?** \\n|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import Row\n",
        "\n",
        "\n",
        "data = [Row(text=pdf_text)]\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "\n",
        "df.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E79Yz5CwwS5",
        "outputId": "c0792c2a-4669-421d-8499-f1ef2da67987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[##, **, Functional, Requirements, **, ###, **, 1, ., Authentication, Handling, &, Session, Management, **, , **, Objective, :**, Identify, weak, authentication, mechanism, ,, insecure, session, handle, ,, credential, exposure, ., , **, Functionalities, :**, -, Test, weak, password, via, **, dictionary, attack, **, (, `requests`, ,, `bcrypt`, )., -, Detect, **, insecure, authentication, mechanism, **, (, e.g, .,, Basic, Auth, ,, JWT, flaw, )., -, Check, **, session, fixation, &, session, hijack, **, vulnerability, ., -, Analyze, **, cooky, miss, security, flag, **, (, HttpOnly, ,, Secure, ,, SameSite, )., -, Validate, **, password, reset, mechanism, **, predictable, token, ., , **, OOP, Design, :**, -, **, Class, :**, `AuthenticationTester`, -, **, Encapsulation, :**, Handles, cookie/token, storage, securely, ., -, **, Inheritance, :**, Supports, different, authentication, type, (, Basic, ,, Form-based, ,, OAuth, )., -, **, Polymorphism, :**, Implements, various, attack, vector, (, brute-force, ,, token, tamper, )., , **, Technologies, :**, -, **, Python, Libraries, :**, `requests`, ,, `selenium`, ,, `jwt`, ,, `bcrypt`, ., -, **, External, Tools, :**, Hydra, (, brute-force, login, attempt, )., ---, ###, **, 2, ., SSL/TLS, Vulnerability, Scanner, **, , **, Objective, :**, Detect, outdated, encryption, protocol, ,, weak, cipher, ,, certificate, misconfigurations, ., , **, Functionalities, :**, -, Check, **, expired/misconfigured, SSL, certificate, **., -, Identify, **, weak, TLS, version, **, (, e.g, .,, TLS, 1.0, ,, SSL, 3.0, )., -, Verify, **, HTTP, Strict, Transport, Security, (, HSTS, ), implementation, **., -, Analyze, **, certificate, chain, trust, issue, **., , **, OOP, Design, :**, -, **, Class, :**, `SSLScanner`, -, **, Encapsulation, :**, Stores, SSL, analysis, logic, separately, ., -, **, Polymorphism, :**, Supports, different, scan, approach, (, OpenSSL, ,, nmap, script, )., , **, Technologies, :**, -, **, Python, Libraries, :**, `sslyze`, ,, `requests`, ., -, **, External, Tools, :**, `nmap, --, script, ssl-*`, ,, `openssl`, ., ---, ###, **, 3, ., File, Directory, Discovery, **, , **, Objective, :**, Locate, hide, sensitive, file, might, expose, security, risk, ., , **, Functionalities, :**, -, Enumerate, **, hide, directory, (, `.git/`, ,, `backup.zip`, )**., -, Detect, **, sensitive, file, (, `config.php`, ,, `.env`, ,, `database.sql`, )**., -, Brute-force, **, directory, path, use, wordlist, **, (, `dirsearch`, )., -, Identify, **, expose, backups/log, file, **, (, `access.log`, ,, `debug.log`, )., -, Check, **, default, web, application, file, **, (, admin, panel, ,, API, doc, )., , **, OOP, Design, :**, -, **, Class, :**, `DirScanner`, -, **, Encapsulation, :**, Manages, wordlist, process, response, parse, ., -, **, Composition, :**, Integrates, `dirsearch`, `ffuf`, brute-force, scan, ., , **, Technologies, :**, -, **, Python, Libraries, :**, `requests`, ,, `BeautifulSoup`, ., -, **, External, Tools, :**, `dirsearch`, ,, `wfuzz`, ,, `ffuf`, ., ---, ###, **, 4, ., API, Scanning, **, , **, Objective, :**, Identify, security, flaw, web, APIs, ,, improper, authentication, ,, excessive, data, exposure, ,, rate-limiting, issue, ., , **, Functionalities, :**, -, Discover, **, expose, API, endpoint, (, OpenAPI, ,, GraphQL, )**., -, Identify, **, API, rate-limiting, issue, **, via, request, flood, ., -, Test, **, IDOR, (, Insecure, Direct, Object, References, )**., -, Analyze, **, improper, authentication/token, management, (, OAuth, ,, JWT, )**., , **, OOP, Design, :**, -, **, Class, :**, `APIScanner`, -, **, Inheritance, :**, Supports, multiple, API, type, (, REST, ,, SOAP, ,, GraphQL, )., -, **, Encapsulation, :**, Separates, authentication, handle, ,, request, generation, ,, response, validation, ., , **, Technologies, :**, -, **, Python, Libraries, :**, `requests`, ,, `jwt`, ,, `BeautifulSoup`, ., -, **, External, Tools, :**, `nmap, -, sV, --, script, http-*`, ,, `Postman, API`, ., ---, ###, **, 5, ., Port, Scanning, **, , **, Objective, :**, Identify, open, port, ,, run, service, ,, potential, vulnerability, ., , **, Functionalities, :**, -, Scan, **, open, port, **, identify, run, service, ., -, Perform, **, TCP, &, UDP, scan, **., -, Detect, **, firewall, intrusion, prevention, mechanism, **., , **, OOP, Design, :**, -, **, Class, :**, `PortScanner`, -, **, Encapsulation, :**, Stores, scan, logic, separately, ., -, **, Polymorphism, :**, Implements, different, scan, type, (, SYN, ,, full-connect, ,, UDP, )., , **, Technologies, :**, -, **, Python, Libraries, :**, `socket`, ,, `scapy`, ., -, **, External, Tools, :**, `nmap`, ,, `masscan`, ., ---, ##, **, 6, ., Reporting, &, Logging, **, , **, Objective, :**, Generate, report, ,, categorize, vulnerability, ,, maintain, log, audit, ., , **, Functionalities, :**, -, Generate, structure, report, (, `JSON`, ,, `CSV`, ,, `TXT`, )., -, Categorize, vulnerability, (, Critical, ,, High, ,, Medium, ,, Low, )., -, Format, output, use, **, rich, text, CLI, (, table, ,, color, )**., -, Maintain, **, detail, log, security, audit, **., , **, OOP, Design, :**, -, **, Class, :**, `ReportGenerator`, -, **, Encapsulation, :**, Manages, data, storage, separately, ., -, **, Composition, :**, Integrates, vulnerability, scanner, aggregate, report, ., , **, Technologies, :**, -, **, Python, Libraries, :**, `pandas`, ,, `json`, ,, `rich`, ., ---, ##, **, CLI, Design, &, Usage, **, ```bash, #, Example, command, python3, pentest_tool.py, --, auth-check, <target_url>, python3, pentest_tool.py, --, ssl-scan, <target_url>, python3, pentest_tool.py, --, dir-scan, <target_url>, --, wordlist, common.txt, python3, pentest_tool.py, --, api-scan, <target_url>, python3, pentest_tool.py, --, port-scan, <target_ip>, python3, pentest_tool.py, --, report, output.json, ```, ---, ##, **, OOP, Benefits, Project, **, , **, Encapsulation, :**, feature, modular, ,, make, code, **, organize, maintainable, **., , **, Inheritance, :**, Common, task, like, send, HTTP, request, **, reuse, across, module, **., , **, Polymorphism, :**, tool, **, handle, multiple, type, scans/vulnerabilities, **, seamlessly, ., , **, Abstraction, :**, Users, **, interact, simple, CLI, command, **,, tool, handle, complexity, background, ., ---, ##, **, Future, Enhancements, **, , **, Multi-threading, fast, scan, **, (, `concurrent.futures`, ,, `asyncio`, )., , **, GUI-based, version, easy, usage, **, (, `PyQt`, `Tkinter`, )., , **, Machine, Learning, module, vulnerability, detection, pattern, **., ---, ##, **, Matters, **, tool, simplify, web, security, **, automate, penetration, test, **,, reduce, manual, effort, security, team, ., Whether, **, developer, ,, security, researcher, ,, ethical, hacker, **,, provide, **, powerful, yet, easy-to-use, solution, **, web, application, security, ., ---, , **, Next, Steps, :, want, generate, basic, Python, class, structure, kickstart, development, ?**, ]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PlagiarismDetection\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "data = [(pdf_text,)]\n",
        "columns = [\"text\"]\n",
        "\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "\n",
        "\n",
        "from sparknlp.base import DocumentAssembler\n",
        "from sparknlp.annotator import Tokenizer, StopWordsCleaner, LemmatizerModel\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "stopwords_cleaner = StopWordsCleaner().setInputCols([\"token\"]).setOutputCol(\"clean_tokens\")\n",
        "lemmatizer = LemmatizerModel.pretrained().setInputCols([\"clean_tokens\"]).setOutputCol(\"lemmatized\")\n",
        "\n",
        "# Build the pipeline\n",
        "pipeline = Pipeline(stages=[document_assembler, tokenizer, stopwords_cleaner, lemmatizer])\n",
        "\n",
        "# Step 3: Apply the pipeline to the DataFrame\n",
        "processed_data = pipeline.fit(df).transform(df)\n",
        "\n",
        "# Step 4: Show the preprocessed data (lemmatized tokens)\n",
        "processed_data.select(\"lemmatized.result\").show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXxk8L9cw8qg"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Extract only the 'result' from the 'lemmatized' column\n",
        "processed_data = processed_data.withColumn(\"lemmatized_tokens\",\n",
        "                                           col(\"lemmatized.result\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftTF92zrxF7x",
        "outputId": "5c902b44-56a1-428b-cba1-223a958df8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|(262144,[92,899,1414,2335,2505,3417,4555,4714,4752,4900,5684,6488,6945,7155,7449,9572,9847,10049,12333,12524,12666,13083,13130,13828,14955,15539,16319,16337,17293,17749,18804,19247,19641,21198,21534,22110,22361,23363,24112,24346,25621,26176,26513,28218,28356,28963,29192,29356,31469,31919,32906,34907,35049,35477,35501,35756,36055,36987,37753,38640,38756,39156,39379,39683,40265,40851,41672,43756,45404,46888,47529,47841,50223,50617,50831,51144,52488,52740,53306,56494,56997,58087,60391,60481,60897,60996,61272,62321,62617,63000,63079,63243,64978,67651,68238,68351,68941,69882,70780,71637,71713,72124,73065,73241,75241,76168,76902,77088,77601,81734,82217,83837,84214,87067,87593,88467,88493,88846,88929,88941,89717,90109,91703,92265,92412,92651,92802,93284,93646,93827,96225,96984,97319,98717,101792,103329,104474,104901,105282,105516,105949,106157,106846,108860,108910,111467,112902,113503,114395,114895,116052,116098,116352,116478,116795,118036,118287,118567,119356,119486,119556,119709,121356,122943,123524,123933,124674,124921,125905,126135,127653,128026,129072,131982,133613,134433,137710,137798,138007,138796,139151,139786,140820,141124,141331,141577,141913,142305,142418,143479,143985,144499,145734,147249,147936,148233,149300,149341,149605,150224,151170,151270,154789,155965,156019,156326,157511,158421,159258,159989,160735,160983,163674,164373,165778,166319,167207,167481,167916,168180,168590,169527,169549,170166,170483,171106,171843,172196,173695,174879,177387,180844,182063,182127,182693,183352,184040,184272,184763,184956,185473,187359,187388,187970,188216,188415,188453,188708,188762,188794,188885,189123,189640,190256,190632,191591,191598,192394,192648,194186,194215,194802,194985,195501,196996,197093,197972,198652,198703,199498,200381,200708,201479,201547,202481,202961,203200,204132,204552,206622,207377,208258,210476,210936,211302,213468,214252,214790,215021,215287,215594,215686,216221,216295,216407,218285,219554,220565,223753,227723,228293,228597,229098,230784,231152,232735,233097,233277,233605,235415,235700,236002,236461,237340,238240,238934,239234,240041,240860,241840,242211,243875,244132,244204,245775,245908,245949,246110,246713,247028,247863,248200,249260,250619,251464,251469,251584,251863,251904,253405,253586,254017,254071,254226,255122,256468,257347,257937,260248,260874,261282],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary classes\n",
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "\n",
        "# Generate term frequency (TF) features\n",
        "hashing_tf = HashingTF(inputCol=\"lemmatized_tokens\", outputCol=\"raw_features\")\n",
        "featurized_data = hashing_tf.transform(processed_data)\n",
        "\n",
        "# Apply IDF (Inverse Document Frequency)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "idf_model = idf.fit(featurized_data)\n",
        "tfidf_data = idf_model.transform(featurized_data)\n",
        "\n",
        "# Show the features (TF-IDF values)\n",
        "tfidf_data.select(\"features\").show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVpPtMFHx3oA",
        "outputId": "72e7e6c3-949b-4534-d678-7d0e06368be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|bigrams                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[## **, ** Functional, Functional Requirements, Requirements **, ** ###, ### **, ** 1, 1 ., . Authentication, Authentication Handling, Handling &, & Session, Session Management, Management **, ** ,  **, ** Objective, Objective :**, :** Identify, Identify weak, weak authentication, authentication mechanism, mechanism ,, , insecure, insecure session, session handle, handle ,, , credential, credential exposure, exposure ., . ,  **, ** Functionalities, Functionalities :**, :** -, - Test, Test weak, weak password, password via, via **, ** dictionary, dictionary attack, attack **, ** (, ( `requests`, `requests` ,, , `bcrypt`, `bcrypt` )., ). -, - Detect, Detect **, ** insecure, insecure authentication, authentication mechanism, mechanism **, ** (, ( e.g, e.g .,, ., Basic, Basic Auth, Auth ,, , JWT, JWT flaw, flaw )., ). -, - Check, Check **, ** session, session fixation, fixation &, & session, session hijack, hijack **, ** vulnerability, vulnerability ., . -, - Analyze, Analyze **, ** cooky, cooky miss, miss security, security flag, flag **, ** (, ( HttpOnly, HttpOnly ,, , Secure, Secure ,, , SameSite, SameSite )., ). -, - Validate, Validate **, ** password, password reset, reset mechanism, mechanism **, ** predictable, predictable token, token ., . ,  **, ** OOP, OOP Design, Design :**, :** -, - **, ** Class, Class :**, :** `AuthenticationTester`, `AuthenticationTester` -, - **, ** Encapsulation, Encapsulation :**, :** Handles, Handles cookie/token, cookie/token storage, storage securely, securely ., . -, - **, ** Inheritance, Inheritance :**, :** Supports, Supports different, different authentication, authentication type, type (, ( Basic, Basic ,, , Form-based, Form-based ,, , OAuth, OAuth )., ). -, - **, ** Polymorphism, Polymorphism :**, :** Implements, Implements various, various attack, attack vector, vector (, ( brute-force, brute-force ,, , token, token tamper, tamper )., ). ,  **, ** Technologies, Technologies :**, :** -, - **, ** Python, Python Libraries, Libraries :**, :** `requests`, `requests` ,, , `selenium`, `selenium` ,, , `jwt`, `jwt` ,, , `bcrypt`, `bcrypt` ., . -, - **, ** External, External Tools, Tools :**, :** Hydra, Hydra (, ( brute-force, brute-force login, login attempt, attempt )., ). ---, --- ###, ### **, ** 2, 2 ., . SSL/TLS, SSL/TLS Vulnerability, Vulnerability Scanner, Scanner **, ** ,  **, ** Objective, Objective :**, :** Detect, Detect outdated, outdated encryption, encryption protocol, protocol ,, , weak, weak cipher, cipher ,, , certificate, certificate misconfigurations, misconfigurations ., . ,  **, ** Functionalities, Functionalities :**, :** -, - Check, Check **, ** expired/misconfigured, expired/misconfigured SSL, SSL certificate, certificate **., **. -, - Identify, Identify **, ** weak, weak TLS, TLS version, version **, ** (, ( e.g, e.g .,, ., TLS, TLS 1.0, 1.0 ,, , SSL, SSL 3.0, 3.0 )., ). -, - Verify, Verify **, ** HTTP, HTTP Strict, Strict Transport, Transport Security, Security (, ( HSTS, HSTS ), ) implementation, implementation **., **. -, - Analyze, Analyze **, ** certificate, certificate chain, chain trust, trust issue, issue **., **. ,  **, ** OOP, OOP Design, Design :**, :** -, - **, ** Class, Class :**, :** `SSLScanner`, `SSLScanner` -, - **, ** Encapsulation, Encapsulation :**, :** Stores, Stores SSL, SSL analysis, analysis logic, logic separately, separately ., . -, - **, ** Polymorphism, Polymorphism :**, :** Supports, Supports different, different scan, scan approach, approach (, ( OpenSSL, OpenSSL ,, , nmap, nmap script, script )., ). ,  **, ** Technologies, Technologies :**, :** -, - **, ** Python, Python Libraries, Libraries :**, :** `sslyze`, `sslyze` ,, , `requests`, `requests` ., . -, - **, ** External, External Tools, Tools :**, :** `nmap, `nmap --, -- script, script ssl-*`, ssl-*` ,, , `openssl`, `openssl` ., . ---, --- ###, ### **, ** 3, 3 ., . File, File Directory, Directory Discovery, Discovery **, ** ,  **, ** Objective, Objective :**, :** Locate, Locate hide, hide sensitive, sensitive file, file might, might expose, expose security, security risk, risk ., . ,  **, ** Functionalities, Functionalities :**, :** -, - Enumerate, Enumerate **, ** hide, hide directory, directory (, ( `.git/`, `.git/` ,, , `backup.zip`, `backup.zip` )**., )**. -, - Detect, Detect **, ** sensitive, sensitive file, file (, ( `config.php`, `config.php` ,, , `.env`, `.env` ,, , `database.sql`, `database.sql` )**., )**. -, - Brute-force, Brute-force **, ** directory, directory path, path use, use wordlist, wordlist **, ** (, ( `dirsearch`, `dirsearch` )., ). -, - Identify, Identify **, ** expose, expose backups/log, backups/log file, file **, ** (, ( `access.log`, `access.log` ,, , `debug.log`, `debug.log` )., ). -, - Check, Check **, ** default, default web, web application, application file, file **, ** (, ( admin, admin panel, panel ,, , API, API doc, doc )., ). ,  **, ** OOP, OOP Design, Design :**, :** -, - **, ** Class, Class :**, :** `DirScanner`, `DirScanner` -, - **, ** Encapsulation, Encapsulation :**, :** Manages, Manages wordlist, wordlist process, process response, response parse, parse ., . -, - **, ** Composition, Composition :**, :** Integrates, Integrates `dirsearch`, `dirsearch` `ffuf`, `ffuf` brute-force, brute-force scan, scan ., . ,  **, ** Technologies, Technologies :**, :** -, - **, ** Python, Python Libraries, Libraries :**, :** `requests`, `requests` ,, , `BeautifulSoup`, `BeautifulSoup` ., . -, - **, ** External, External Tools, Tools :**, :** `dirsearch`, `dirsearch` ,, , `wfuzz`, `wfuzz` ,, , `ffuf`, `ffuf` ., . ---, --- ###, ### **, ** 4, 4 ., . API, API Scanning, Scanning **, ** ,  **, ** Objective, Objective :**, :** Identify, Identify security, security flaw, flaw web, web APIs, APIs ,, , improper, improper authentication, authentication ,, , excessive, excessive data, data exposure, exposure ,, , rate-limiting, rate-limiting issue, issue ., . ,  **, ** Functionalities, Functionalities :**, :** -, - Discover, Discover **, ** expose, expose API, API endpoint, endpoint (, ( OpenAPI, OpenAPI ,, , GraphQL, GraphQL )**., )**. -, - Identify, Identify **, ** API, API rate-limiting, rate-limiting issue, issue **, ** via, via request, request flood, flood ., . -, - Test, Test **, ** IDOR, IDOR (, ( Insecure, Insecure Direct, Direct Object, Object References, References )**., )**. -, - Analyze, Analyze **, ** improper, improper authentication/token, authentication/token management, management (, ( OAuth, OAuth ,, , JWT, JWT )**., )**. ,  **, ** OOP, OOP Design, Design :**, :** -, - **, ** Class, Class :**, :** `APIScanner`, `APIScanner` -, - **, ** Inheritance, Inheritance :**, :** Supports, Supports multiple, multiple API, API type, type (, ( REST, REST ,, , SOAP, SOAP ,, , GraphQL, GraphQL )., ). -, - **, ** Encapsulation, Encapsulation :**, :** Separates, Separates authentication, authentication handle, handle ,, , request, request generation, generation ,, , response, response validation, validation ., . ,  **, ** Technologies, Technologies :**, :** -, - **, ** Python, Python Libraries, Libraries :**, :** `requests`, `requests` ,, , `jwt`, `jwt` ,, , `BeautifulSoup`, `BeautifulSoup` ., . -, - **, ** External, External Tools, Tools :**, :** `nmap, `nmap -, - sV, sV --, -- script, script http-*`, http-*` ,, , `Postman, `Postman API`, API` ., . ---, --- ###, ### **, ** 5, 5 ., . Port, Port Scanning, Scanning **, ** ,  **, ** Objective, Objective :**, :** Identify, Identify open, open port, port ,, , run, run service, service ,, , potential, potential vulnerability, vulnerability ., . ,  **, ** Functionalities, Functionalities :**, :** -, - Scan, Scan **, ** open, open port, port **, ** identify, identify run, run service, service ., . -, - Perform, Perform **, ** TCP, TCP &, & UDP, UDP scan, scan **., **. -, - Detect, Detect **, ** firewall, firewall intrusion, intrusion prevention, prevention mechanism, mechanism **., **. ,  **, ** OOP, OOP Design, Design :**, :** -, - **, ** Class, Class :**, :** `PortScanner`, `PortScanner` -, - **, ** Encapsulation, Encapsulation :**, :** Stores, Stores scan, scan logic, logic separately, separately ., . -, - **, ** Polymorphism, Polymorphism :**, :** Implements, Implements different, different scan, scan type, type (, ( SYN, SYN ,, , full-connect, full-connect ,, , UDP, UDP )., ). ,  **, ** Technologies, Technologies :**, :** -, - **, ** Python, Python Libraries, Libraries :**, :** `socket`, `socket` ,, , `scapy`, `scapy` ., . -, - **, ** External, External Tools, Tools :**, :** `nmap`, `nmap` ,, , `masscan`, `masscan` ., . ---, --- ##, ## **, ** 6, 6 ., . Reporting, Reporting &, & Logging, Logging **, ** ,  **, ** Objective, Objective :**, :** Generate, Generate report, report ,, , categorize, categorize vulnerability, vulnerability ,, , maintain, maintain log, log audit, audit ., . ,  **, ** Functionalities, Functionalities :**, :** -, - Generate, Generate structure, structure report, report (, ( `JSON`, `JSON` ,, , `CSV`, `CSV` ,, , `TXT`, `TXT` )., ). -, - Categorize, Categorize vulnerability, vulnerability (, ( Critical, Critical ,, , High, High ,, , Medium, Medium ,, , Low, Low )., ). -, - Format, Format output, output use, use **, ** rich, rich text, text CLI, CLI (, ( table, table ,, , color, color )**., )**. -, - Maintain, Maintain **, ** detail, detail log, log security, security audit, audit **., **. ,  **, ** OOP, OOP Design, Design :**, :** -, - **, ** Class, Class :**, :** `ReportGenerator`, `ReportGenerator` -, - **, ** Encapsulation, Encapsulation :**, :** Manages, Manages data, data storage, storage separately, separately ., . -, - **, ** Composition, Composition :**, :** Integrates, Integrates vulnerability, vulnerability scanner, scanner aggregate, aggregate report, report ., . ,  **, ** Technologies, Technologies :**, :** -, - **, ** Python, Python Libraries, Libraries :**, :** `pandas`, `pandas` ,, , `json`, `json` ,, , `rich`, `rich` ., . ---, --- ##, ## **, ** CLI, CLI Design, Design &, & Usage, Usage **, ** ```bash, ```bash #, # Example, Example command, command python3, python3 pentest_tool.py, pentest_tool.py --, -- auth-check, auth-check <target_url>, <target_url> python3, python3 pentest_tool.py, pentest_tool.py --, -- ssl-scan, ssl-scan <target_url>, <target_url> python3, python3 pentest_tool.py, pentest_tool.py --, -- dir-scan, dir-scan <target_url>, <target_url> --, -- wordlist, wordlist common.txt, common.txt python3, python3 pentest_tool.py, pentest_tool.py --, -- api-scan, api-scan <target_url>, <target_url> python3, python3 pentest_tool.py, pentest_tool.py --, -- port-scan, port-scan <target_ip>, <target_ip> python3, python3 pentest_tool.py, pentest_tool.py --, -- report, report output.json, output.json ```, ``` ---, --- ##, ## **, ** OOP, OOP Benefits, Benefits Project, Project **, ** ,  **, ** Encapsulation, Encapsulation :**, :** feature, feature modular, modular ,, , make, make code, code **, ** organize, organize maintainable, maintainable **., **. ,  **, ** Inheritance, Inheritance :**, :** Common, Common task, task like, like send, send HTTP, HTTP request, request **, ** reuse, reuse across, across module, module **., **. ,  **, ** Polymorphism, Polymorphism :**, :** tool, tool **, ** handle, handle multiple, multiple type, type scans/vulnerabilities, scans/vulnerabilities **, ** seamlessly, seamlessly ., . ,  **, ** Abstraction, Abstraction :**, :** Users, Users **, ** interact, interact simple, simple CLI, CLI command, command **,, **, tool, tool handle, handle complexity, complexity background, background ., . ---, --- ##, ## **, ** Future, Future Enhancements, Enhancements **, ** ,  **, ** Multi-threading, Multi-threading fast, fast scan, scan **, ** (, ( `concurrent.futures`, `concurrent.futures` ,, , `asyncio`, `asyncio` )., ). ,  **, ** GUI-based, GUI-based version, version easy, easy usage, usage **, ** (, ( `PyQt`, `PyQt` `Tkinter`, `Tkinter` )., ). ,  **, ** Machine, Machine Learning, Learning module, module vulnerability, vulnerability detection, detection pattern, pattern **., **. ---, --- ##, ## **, ** Matters, Matters **, ** tool, tool simplify, simplify web, web security, security **, ** automate, automate penetration, penetration test, test **,, **, reduce, reduce manual, manual effort, effort security, security team, team ., . Whether, Whether **, ** developer, developer ,, , security, security researcher, researcher ,, , ethical, ethical hacker, hacker **,, **, provide, provide **, ** powerful, powerful yet, yet easy-to-use, easy-to-use solution, solution **, ** web, web application, application security, security ., . ---, --- ,  **, ** Next, Next Steps, Steps :, : want, want generate, generate basic, basic Python, Python class, class structure, structure kickstart, kickstart development, development ?**, ?** ]|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import NGram\n",
        "\n",
        "# Generate bigrams (n=2)\n",
        "ngram = NGram(n=2, inputCol=\"lemmatized_tokens\", outputCol=\"bigrams\")\n",
        "ngram_data = ngram.transform(processed_data)\n",
        "\n",
        "# Show the bigrams\n",
        "ngram_data.select(\"bigrams\").show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPnyJbwix6xg"
      },
      "outputs": [],
      "source": [
        "# Save the processed data to a Parquet file and overwrite if it exists\n",
        "processed_data.write.mode(\"overwrite\").format(\"parquet\").save(\"/content/processed_data.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ENyo6TTzF-Q",
        "outputId": "375b4501-503a-4444-b908-1cb6ffacebba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BUSVlazzIzA",
        "outputId": "737741bb-067d-4469-bfa7-1981fb0751a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4NBpNl6zSGg",
        "outputId": "8dec7f1d-78d1-4113-cabb-b6624201856c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting apache-airflow\n",
            "  Downloading apache_airflow-2.10.5-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/45.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic<2.0,>=1.13.1 (from apache-airflow)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting argcomplete>=1.10 (from apache-airflow)\n",
            "  Downloading argcomplete-3.6.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting asgiref>=2.3.0 (from apache-airflow)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: attrs>=22.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (25.3.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.9.0)\n",
            "Collecting colorlog>=6.8.2 (from apache-airflow)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting configupdater>=3.1.1 (from apache-airflow)\n",
            "  Downloading ConfigUpdater-3.2-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting connexion<3.0,>=2.14.2 (from connexion[flask]<3.0,>=2.14.2->apache-airflow)\n",
            "  Downloading connexion-2.14.2-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting cron-descriptor>=1.2.24 (from apache-airflow)\n",
            "  Downloading cron_descriptor-1.4.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting croniter>=2.0.2 (from apache-airflow)\n",
            "  Downloading croniter-6.0.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: cryptography>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (43.0.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.2.18)\n",
            "Collecting dill>=0.2.2 (from apache-airflow)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting flask-caching>=2.0.0 (from apache-airflow)\n",
            "  Downloading Flask_Caching-2.3.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting flask-session<0.6,>=0.4.0 (from apache-airflow)\n",
            "  Downloading flask_session-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting flask-wtf>=1.1.0 (from apache-airflow)\n",
            "  Downloading flask_wtf-1.2.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting flask<2.3,>=2.2.1 (from apache-airflow)\n",
            "  Downloading Flask-2.2.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2025.3.2)\n",
            "Collecting google-re2>=1.0 (from apache-airflow)\n",
            "  Downloading google_re2-1.1.20240702-1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting gunicorn>=20.1.0 (from apache-airflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.28.1)\n",
            "Requirement already satisfied: importlib_metadata>=6.5 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (8.6.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (4.23.0)\n",
            "Collecting lazy-object-proxy>=1.2.0 (from apache-airflow)\n",
            "  Downloading lazy_object_proxy-1.10.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: linkify-it-py>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.0.3)\n",
            "Collecting lockfile>=0.12.2 (from apache-airflow)\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.0.0)\n",
            "Requirement already satisfied: markupsafe>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.0.2)\n",
            "Collecting marshmallow-oneofschema>=2.0.1 (from apache-airflow)\n",
            "  Downloading marshmallow_oneofschema-3.1.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: mdit-py-plugins>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.4.2)\n",
            "Collecting methodtools>=0.4.7 (from apache-airflow)\n",
            "  Downloading methodtools-0.4.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp>=1.24.0 (from apache-airflow)\n",
            "  Downloading opentelemetry_exporter_otlp-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (24.2)\n",
            "Collecting pathspec>=0.9.0 (from apache-airflow)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pendulum<4.0,>=2.1.2 (from apache-airflow)\n",
            "  Downloading pendulum-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pluggy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.5.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (5.9.5)\n",
            "Requirement already satisfied: pygments>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.18.0)\n",
            "Requirement already satisfied: pyjwt>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.10.1)\n",
            "Collecting python-daemon>=3.0.0 (from apache-airflow)\n",
            "  Downloading python_daemon-3.1.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.8.2)\n",
            "Collecting python-nvd3>=0.15.0 (from apache-airflow)\n",
            "  Downloading python-nvd3-0.16.0.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-slugify>=5.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (8.0.4)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.0.0)\n",
            "Collecting rfc3339-validator>=0.1.4 (from apache-airflow)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rich-argparse>=1.0.0 (from apache-airflow)\n",
            "  Downloading rich_argparse-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: rich>=12.4.4 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (13.9.4)\n",
            "Requirement already satisfied: setproctitle>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.3.5)\n",
            "Collecting sqlalchemy<2.0,>=1.4.36 (from apache-airflow)\n",
            "  Downloading SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting sqlalchemy-jsonfield>=1.0 (from apache-airflow)\n",
            "  Downloading SQLAlchemy_JSONField-1.0.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.9.0)\n",
            "Requirement already satisfied: tenacity!=8.2.0,>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (9.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.0.1)\n",
            "Collecting universal-pathlib!=0.2.4,>=0.2.2 (from apache-airflow)\n",
            "  Downloading universal_pathlib-0.2.6-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting werkzeug<3,>=2.0 (from apache-airflow)\n",
            "  Downloading werkzeug-2.3.8-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting apache-airflow-providers-common-compat (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_common_compat-1.6.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting apache-airflow-providers-common-io (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_common_io-1.5.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting apache-airflow-providers-common-sql (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_common_sql-1.25.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting apache-airflow-providers-fab>=1.0.2 (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_fab-2.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting apache-airflow-providers-ftp (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_ftp-3.12.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting apache-airflow-providers-http (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_http-5.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting apache-airflow-providers-imap (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_imap-3.8.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting apache-airflow-providers-smtp (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_smtp-2.0.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting apache-airflow-providers-sqlite (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_sqlite-4.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0,>=1.13.1->apache-airflow) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic<2.0,>=1.13.1->apache-airflow) (4.13.1)\n",
            "INFO: pip is looking at multiple versions of apache-airflow-providers-fab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting apache-airflow-providers-fab>=1.0.2 (from apache-airflow)\n",
            "  Downloading apache_airflow_providers_fab-1.5.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting flask-appbuilder==4.5.3 (from apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading Flask_AppBuilder-4.5.3-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting flask-login>=0.6.2 (from apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading Flask_Login-0.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jmespath>=0.7.0 (from apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting apispec<7,>=6.0.0 (from apispec[yaml]<7,>=6.0.0->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading apispec-6.8.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting colorama<1,>=0.3.9 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: click<9,>=8 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (8.1.8)\n",
            "Collecting email-validator>=1.0.5 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting Flask-Babel<3,>=1 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading Flask_Babel-2.0.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting Flask-Limiter<4,>3 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading flask_limiter-3.12-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting Flask-SQLAlchemy<3,>=2.4 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading Flask_SQLAlchemy-2.5.1-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting Flask-JWT-Extended<5.0.0,>=4.0.0 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading Flask_JWT_Extended-4.7.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting marshmallow<4,>=3.18.0 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting marshmallow-sqlalchemy<0.29.0,>=0.22.0 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading marshmallow_sqlalchemy-0.28.2-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting prison<1.0.0,>=0.2.1 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading prison-0.2.1-py2.py3-none-any.whl.metadata (973 bytes)\n",
            "Collecting sqlalchemy-utils<1,>=0.32.21 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading SQLAlchemy_Utils-0.41.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting WTForms<4 (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading wtforms-3.2.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting clickclick<21,>=1.2 (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow)\n",
            "  Downloading clickclick-20.10.2-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: PyYAML<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow) (6.0.2)\n",
            "Collecting inflection<0.6,>=0.3.1 (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow)\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting werkzeug<3,>=2.0 (from apache-airflow)\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: pytz>2021.1 in /usr/local/lib/python3.11/dist-packages (from croniter>=2.0.2->apache-airflow) (2025.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=41.0.0->apache-airflow) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->apache-airflow) (1.17.2)\n",
            "Collecting cachelib>=0.9.0 (from flask-caching>=2.0.0->apache-airflow)\n",
            "  Downloading cachelib-0.13.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->apache-airflow) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=6.5->apache-airflow) (3.21.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->apache-airflow) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->apache-airflow) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->apache-airflow) (0.24.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py>=2.0.0->apache-airflow) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.1.0->apache-airflow) (0.1.2)\n",
            "Collecting wirerope>=0.4.7 (from methodtools>=0.4.7->apache-airflow)\n",
            "  Downloading wirerope-1.0.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.32.1 (from opentelemetry-exporter-otlp>=1.24.0->apache-airflow)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.32.1 (from opentelemetry-exporter-otlp>=1.24.0->apache-airflow)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.69.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp>=1.24.0->apache-airflow)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp>=1.24.0->apache-airflow)\n",
            "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk~=1.32.1 (from opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp>=1.24.0->apache-airflow)\n",
            "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (5.29.4)\n",
            "Requirement already satisfied: tzdata>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pendulum<4.0,>=2.1.2->apache-airflow) (2025.2)\n",
            "Collecting time-machine>=2.6.0 (from pendulum<4.0,>=2.1.2->apache-airflow)\n",
            "  Downloading time_machine-2.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->apache-airflow) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify>=5.0->apache-airflow) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->apache-airflow) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->apache-airflow) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.0,>=1.4.36->apache-airflow) (3.1.1)\n",
            "Requirement already satisfied: sqlparse>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-common-sql->apache-airflow) (0.5.3)\n",
            "Requirement already satisfied: more-itertools>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-common-sql->apache-airflow) (10.6.0)\n",
            "Requirement already satisfied: aiohttp!=3.11.0,>=3.9.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-http->apache-airflow) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.19.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=41.0.0->apache-airflow) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->apache-airflow) (1.3.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=1.0.5->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.7.0)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.11/dist-packages (from Flask-Babel<3,>=1->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.17.0)\n",
            "Collecting limits>=3.13 (from Flask-Limiter<4,>3->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading limits-5.0.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting ordered-set<5,>4 (from Flask-Limiter<4,>3->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opentelemetry-api>=1.24.0 (from apache-airflow)\n",
            "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-sdk~=1.32.1->opentelemetry-exporter-otlp-proto-grpc==1.32.1->opentelemetry-exporter-otlp>=1.24.0->apache-airflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading apache_airflow-2.10.5-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_airflow_providers_fab-1.5.3-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_AppBuilder-4.5.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_airflow_providers_common_compat-1.6.0-py3-none-any.whl (30 kB)\n",
            "Downloading argcomplete-3.6.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading ConfigUpdater-3.2-py2.py3-none-any.whl (34 kB)\n",
            "Downloading connexion-2.14.2-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cron_descriptor-1.4.5-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading croniter-6.0.0-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask-2.2.5-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Caching-2.3.1-py3-none-any.whl (28 kB)\n",
            "Downloading flask_session-0.5.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading flask_wtf-1.2.2-py3-none-any.whl (12 kB)\n",
            "Downloading google_re2-1.1.20240702-1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m548.4/548.4 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_object_proxy-1.10.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Downloading marshmallow_oneofschema-3.1.1-py3-none-any.whl (5.7 kB)\n",
            "Downloading methodtools-0.4.7-py2.py3-none-any.whl (4.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.32.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pendulum-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_daemon-3.1.2-py3-none-any.whl (30 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading rich_argparse-1.7.0-py3-none-any.whl (25 kB)\n",
            "Downloading SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy_JSONField-1.0.2-py3-none-any.whl (10 kB)\n",
            "Downloading universal_pathlib-0.2.6-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_airflow_providers_common_io-1.5.3-py3-none-any.whl (19 kB)\n",
            "Downloading apache_airflow_providers_common_sql-1.25.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_airflow_providers_ftp-3.12.3-py3-none-any.whl (18 kB)\n",
            "Downloading apache_airflow_providers_http-5.2.1-py3-none-any.whl (28 kB)\n",
            "Downloading apache_airflow_providers_imap-3.8.3-py3-none-any.whl (16 kB)\n",
            "Downloading apache_airflow_providers_smtp-2.0.2-py3-none-any.whl (21 kB)\n",
            "Downloading apache_airflow_providers_sqlite-4.0.2-py3-none-any.whl (11 kB)\n",
            "Downloading cachelib-0.13.0-py3-none-any.whl (20 kB)\n",
            "Downloading clickclick-20.10.2-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading Flask_Login-0.6.3-py3-none-any.whl (17 kB)\n",
            "Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading time_machine-2.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Downloading wirerope-1.0.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Downloading wtforms-3.2.1-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apispec-6.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading Flask_JWT_Extended-4.7.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading flask_limiter-3.12-py3-none-any.whl (28 kB)\n",
            "Downloading Flask_SQLAlchemy-2.5.1-py2.py3-none-any.whl (17 kB)\n",
            "Downloading marshmallow_sqlalchemy-0.28.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prison-0.2.1-py2.py3-none-any.whl (5.8 kB)\n",
            "Downloading SQLAlchemy_Utils-0.41.2-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading limits-5.0.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: python-nvd3\n",
            "  Building wheel for python-nvd3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-nvd3: filename=python_nvd3-0.16.0-py3-none-any.whl size=37572 sha256=8faaf15b2c9b4dd2dea2e281a10703dd7e3b573b0393e1b7652f708962809058\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/26/3f/0695457939a8025f982dca665d4d7018468ccf8ccf43e45c5f\n",
            "Successfully built python-nvd3\n",
            "Installing collected packages: lockfile, cron-descriptor, WTForms, wirerope, werkzeug, universal-pathlib, sqlalchemy, rfc3339-validator, python-daemon, prison, pathspec, ordered-set, opentelemetry-proto, marshmallow, lazy-object-proxy, jmespath, inflection, gunicorn, google-re2, email-validator, dill, configupdater, colorlog, colorama, clickclick, cachelib, asgiref, argcomplete, apispec, time-machine, sqlalchemy-utils, sqlalchemy-jsonfield, python-nvd3, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, methodtools, marshmallow-sqlalchemy, marshmallow-oneofschema, limits, flask, croniter, alembic, rich-argparse, pendulum, opentelemetry-semantic-conventions, flask-wtf, Flask-SQLAlchemy, flask-session, flask-login, Flask-Limiter, Flask-JWT-Extended, flask-caching, Flask-Babel, opentelemetry-sdk, flask-appbuilder, connexion, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-exporter-otlp, apache-airflow-providers-common-sql, apache-airflow-providers-common-compat, apache-airflow-providers-sqlite, apache-airflow-providers-smtp, apache-airflow-providers-imap, apache-airflow-providers-http, apache-airflow-providers-ftp, apache-airflow-providers-fab, apache-airflow-providers-common-io, apache-airflow\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.40\n",
            "    Uninstalling SQLAlchemy-2.0.40:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.40\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.31.1\n",
            "    Uninstalling opentelemetry-api-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.31.1\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.31.1\n",
            "    Uninstalling opentelemetry-sdk-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.31.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.54 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-Babel-2.0.0 Flask-JWT-Extended-4.7.1 Flask-Limiter-3.12 Flask-SQLAlchemy-2.5.1 WTForms-3.2.1 alembic-1.15.2 apache-airflow-2.10.5 apache-airflow-providers-common-compat-1.6.0 apache-airflow-providers-common-io-1.5.3 apache-airflow-providers-common-sql-1.25.0 apache-airflow-providers-fab-1.5.3 apache-airflow-providers-ftp-3.12.3 apache-airflow-providers-http-5.2.1 apache-airflow-providers-imap-3.8.3 apache-airflow-providers-smtp-2.0.2 apache-airflow-providers-sqlite-4.0.2 apispec-6.8.1 argcomplete-3.6.2 asgiref-3.8.1 cachelib-0.13.0 clickclick-20.10.2 colorama-0.4.6 colorlog-6.9.0 configupdater-3.2 connexion-2.14.2 cron-descriptor-1.4.5 croniter-6.0.0 dill-0.4.0 email-validator-2.2.0 flask-2.2.5 flask-appbuilder-4.5.3 flask-caching-2.3.1 flask-login-0.6.3 flask-session-0.5.0 flask-wtf-1.2.2 google-re2-1.1.20240702 gunicorn-23.0.0 inflection-0.5.1 jmespath-1.0.1 lazy-object-proxy-1.10.0 limits-5.0.0 lockfile-0.12.2 marshmallow-3.26.1 marshmallow-oneofschema-3.1.1 marshmallow-sqlalchemy-0.28.2 methodtools-0.4.7 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-exporter-otlp-proto-http-1.32.1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 ordered-set-4.1.0 pathspec-0.12.1 pendulum-3.0.0 prison-0.2.1 python-daemon-3.1.2 python-nvd3-0.16.0 rfc3339-validator-0.1.4 rich-argparse-1.7.0 sqlalchemy-1.4.54 sqlalchemy-jsonfield-1.0.2 sqlalchemy-utils-0.41.2 time-machine-2.16.0 universal-pathlib-0.2.6 werkzeug-2.2.3 wirerope-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install apache-airflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVCvBG1YznGA",
        "outputId": "201b450c-60f7-4821-ee62-964a411a22f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.1.5-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading kafka_python-2.1.5-py2.py3-none-any.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m285.4/285.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install kafka-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm8mJpaG_e3Y",
        "outputId": "cccdd957-da95-43f9-8e62-628a6e883e4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldiCPFT_zul_",
        "outputId": "93250336-1cc0-46b5-86ba-65a23fe2e77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Generated Query:  security scanning identify oop\n",
            "\n",
            " Fetching Similar Articles from arXiv...\n",
            "\n",
            "Article 1:\n",
            "{\n",
            "  \"title\": \"Oops!...I think I scanned a malware\",\n",
            "  \"authors\": [\n",
            "    \"Ben Nassi\",\n",
            "    \"Adi Shamir\",\n",
            "    \"Yuval Elovici\"\n",
            "  ],\n",
            "  \"abstract\": \"  This article presents a proof-of-concept illustrating the feasibility of\\ncreating a covert channel between a C\\\\&C server and a malware installed in an\\norganization by exploiting an organization's scanner and using it as a means of\\ninteraction. We take advantage of the light sensitivity of a flatbed scanner,\\nusing a light source to infiltrate data to an organization. We present an\\nimplementation of the method for different purposes (even to trigger a\\nransomware attack) in various experimental setups using: (1) a laser connected\\nto a stand (2) a laser carried by a drone, and (3) a hijacked smart bulb within\\nthe targeted organization from a passing car. In our experiments we were able\\nto infiltrate data using different types of light sources (including infrared\\nlight), from a distance of up to 900 meters away from the scanner. We discuss\\npotential counter measures to prevent the attack.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/1703.07751v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 2:\n",
            "{\n",
            "  \"title\": \"NOOP: A Domain-Theoretic Model of Nominally-Typed OOP\",\n",
            "  \"authors\": [\n",
            "    \"Moez AbdelGawad\",\n",
            "    \"Robert Cartwright\"\n",
            "  ],\n",
            "  \"abstract\": \"  The majority of industrial-strength object-oriented (OO) software is written\\nusing nominally-typed OO programming languages. Extant domain-theoretic models\\nof OOP developed to analyze OO type systems miss, however, a crucial feature of\\nthese mainstream OO languages: nominality. This paper presents the construction\\nof NOOP as the first domain-theoretic model of OOP that includes full\\nclass/type names information found in nominally-typed OOP. Inclusion of nominal\\ninformation in objects of NOOP and asserting that type inheritance in\\nstatically-typed OO programming languages is an inherently nominal notion allow\\nreadily proving that type inheritance and subtyping are completely identified\\nin these languages. This conclusion is in full agreement with intuitions of\\ndevelopers and language designers of these OO languages, and contrary to the\\nbelief that \\\"inheritance is not subtyping,\\\" which came from assuming\\nnon-nominal (a.k.a., structural) models of OOP.\\n  To motivate the construction of NOOP, this paper briefly presents the\\nbenefits of nominal-typing to mainstream OO developers and OO language\\ndesigners, as compared to structural-typing. After presenting NOOP, the paper\\nfurther briefly compares NOOP to the most widely known domain-theoretic models\\nof OOP. Leveraging the development of NOOP, the comparisons presented in this\\npaper provide clear, brief and precise technical and mathematical accounts for\\nthe relation between nominal and structural OO type systems. NOOP, thus,\\nprovides a firmer semantic foundation for analyzing and progressing\\nnominally-typed OO programming languages.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/1801.06793v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 3:\n",
            "{\n",
            "  \"title\": \"Scan Correlation -- Revealing distributed scan campaigns\",\n",
            "  \"authors\": [\n",
            "    \"Steffen Haas\",\n",
            "    \"Florian Wilkens\",\n",
            "    \"Mathias Fischer\"\n",
            "  ],\n",
            "  \"abstract\": \"  Public networks are exposed to port scans from the Internet. Attackers search\\nfor vulnerable services they can exploit. In large scan campaigns, attackers\\noften utilize different machines to perform distributed scans, which impedes\\ntheir detection and might also camouflage the actual goal of the scanning\\ncampaign. In this paper, we present a correlation algorithm to detect scans,\\nidentify potential relations among them, and reassemble them to larger\\ncampaigns. We evaluate our approach on real-world Internet traffic and our\\nresults indicate that it can summarize and characterize standalone and\\ndistributed scan campaigns based on their tools and intention.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/2003.05188v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 4:\n",
            "{\n",
            "  \"title\": \"Semantics-based Privacy by Design for Internet of Things Applications\",\n",
            "  \"authors\": [\n",
            "    \"Lamya Alkhariji\",\n",
            "    \"Suparna De\",\n",
            "    \"Omer Rana\",\n",
            "    \"Charith Perera\"\n",
            "  ],\n",
            "  \"abstract\": \"  As Internet of Things (IoT) technologies become more widespread in everyday\\nlife, privacy issues are becoming more prominent. The aim of this research is\\nto develop a personal assistant that can answer software engineers' questions\\nabout Privacy by Design (PbD) practices during the design phase of IoT system\\ndevelopment. Semantic web technologies are used to model the knowledge\\nunderlying PbD measurements, their intersections with privacy patterns, IoT\\nsystem requirements and the privacy patterns that should be applied across IoT\\nsystems. This is achieved through the development of the PARROT ontology,\\ndeveloped through a set of representative IoT use cases relevant for software\\ndevelopers. This was supported by gathering Competency Questions (CQs) through\\na series of workshops, resulting in 81 curated CQs. These CQs were then\\nrecorded as SPARQL queries, and the developed ontology was evaluated using the\\nCommon Pitfalls model with the help of the Prot\\\\'eg\\\\'e HermiT Reasoner and the\\nOntology Pitfall Scanner (OOPS!), as well as evaluation by external experts.\\nThe ontology was assessed within a user study that identified that the PARROT\\nontology can answer up to 58\\\\% of privacy-related questions from software\\nengineers.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/2210.01778v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 5:\n",
            "{\n",
            "  \"title\": \"Identifying and characterizing ZMap scans: a cryptanalytic approach\",\n",
            "  \"authors\": [\n",
            "    \"Johan Mazel\",\n",
            "    \"R\\u00e9mi Strullu\"\n",
            "  ],\n",
            "  \"abstract\": \"  Network scanning tools play a major role in Internet security. They are used\\nby both network security researchers and malicious actors to identify\\nvulnerable machines exposed on the Internet. ZMap is one of the most common\\nprobing tools for high-speed Internet-wide scanning. We present novel\\nidentification methods based on the IPv4 iteration process of ZMap. These\\nmethods can be used to identify ZMap scans with a small number of addresses\\nextracted from the scan. We conduct an experimental evaluation of these\\ndetection methods on synthetic, network telescope, and backbone traffic. We\\nmanage to identify 28.5% of the ZMap scans in real-world traffic. We then\\nperform an in-depth characterization of these scans regarding, for example,\\ntargeted prefix and probing speed.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/1908.04193v2\"\n",
            "}\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "# --- STEP 1: Read input document ---\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "# --- STEP 2: Extract keyword-based query ---\n",
        "def generate_query(text, num_keywords=5):\n",
        "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    words = text.split()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [w for w in words if w not in stop_words]\n",
        "    most_common = Counter(filtered_words).most_common(num_keywords)\n",
        "    keywords = [word for word, count in most_common]\n",
        "    return \" \".join(keywords)\n",
        "\n",
        "# --- STEP 3: Fetch articles from arXiv ---\n",
        "def fetch_arxiv_articles(query, max_results=5):\n",
        "    search_url = f'http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}'\n",
        "    response = requests.get(search_url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, 'xml')\n",
        "    articles = []\n",
        "    for entry in soup.find_all('entry'):\n",
        "        title = entry.title.text\n",
        "        authors = [author.find('name').text for author in entry.find_all('author')]\n",
        "        abstract = entry.summary.text\n",
        "        url = entry.id.text\n",
        "        articles.append({\n",
        "            'title': title,\n",
        "            'authors': authors,\n",
        "            'abstract': abstract,\n",
        "            'url': url\n",
        "        })\n",
        "    return articles\n",
        "\n",
        "# --- MAIN ---\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"user_input.txt\"  # Replace with your file path\n",
        "    doc_text = read_text_file(file_path)\n",
        "\n",
        "    generated_query = generate_query(doc_text)\n",
        "    print(f\" Generated Query: {generated_query}\")\n",
        "\n",
        "    print(\"\\n Fetching Similar Articles from arXiv...\\n\")\n",
        "    arxiv_results = fetch_arxiv_articles(generated_query)\n",
        "\n",
        "    for idx, article in enumerate(arxiv_results, 1):\n",
        "        print(f\"Article {idx}:\")\n",
        "        print(json.dumps(article, indent=2))\n",
        "        print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJyMW9UF_j_Q",
        "outputId": "5088212d-db22-4b87-cdaa-96e365ec6d52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSr1i1yp_wWC"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/user_input.txt\", 'r', encoding='utf-8') as f:\n",
        "    pdf_text = f.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnqzr7gm_594",
        "outputId": "d68212a5-75bf-4e27-fcf7-4be11e19ceb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Generated Query:  security scanning identify oop\n",
            "\n",
            " Fetching Similar Articles from arXiv...\n",
            "\n",
            "Article 1:\n",
            "{\n",
            "  \"title\": \"Oops!...I think I scanned a malware\",\n",
            "  \"authors\": [\n",
            "    \"Ben Nassi\",\n",
            "    \"Adi Shamir\",\n",
            "    \"Yuval Elovici\"\n",
            "  ],\n",
            "  \"abstract\": \"  This article presents a proof-of-concept illustrating the feasibility of\\ncreating a covert channel between a C\\\\&C server and a malware installed in an\\norganization by exploiting an organization's scanner and using it as a means of\\ninteraction. We take advantage of the light sensitivity of a flatbed scanner,\\nusing a light source to infiltrate data to an organization. We present an\\nimplementation of the method for different purposes (even to trigger a\\nransomware attack) in various experimental setups using: (1) a laser connected\\nto a stand (2) a laser carried by a drone, and (3) a hijacked smart bulb within\\nthe targeted organization from a passing car. In our experiments we were able\\nto infiltrate data using different types of light sources (including infrared\\nlight), from a distance of up to 900 meters away from the scanner. We discuss\\npotential counter measures to prevent the attack.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/1703.07751v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 2:\n",
            "{\n",
            "  \"title\": \"NOOP: A Domain-Theoretic Model of Nominally-Typed OOP\",\n",
            "  \"authors\": [\n",
            "    \"Moez AbdelGawad\",\n",
            "    \"Robert Cartwright\"\n",
            "  ],\n",
            "  \"abstract\": \"  The majority of industrial-strength object-oriented (OO) software is written\\nusing nominally-typed OO programming languages. Extant domain-theoretic models\\nof OOP developed to analyze OO type systems miss, however, a crucial feature of\\nthese mainstream OO languages: nominality. This paper presents the construction\\nof NOOP as the first domain-theoretic model of OOP that includes full\\nclass/type names information found in nominally-typed OOP. Inclusion of nominal\\ninformation in objects of NOOP and asserting that type inheritance in\\nstatically-typed OO programming languages is an inherently nominal notion allow\\nreadily proving that type inheritance and subtyping are completely identified\\nin these languages. This conclusion is in full agreement with intuitions of\\ndevelopers and language designers of these OO languages, and contrary to the\\nbelief that \\\"inheritance is not subtyping,\\\" which came from assuming\\nnon-nominal (a.k.a., structural) models of OOP.\\n  To motivate the construction of NOOP, this paper briefly presents the\\nbenefits of nominal-typing to mainstream OO developers and OO language\\ndesigners, as compared to structural-typing. After presenting NOOP, the paper\\nfurther briefly compares NOOP to the most widely known domain-theoretic models\\nof OOP. Leveraging the development of NOOP, the comparisons presented in this\\npaper provide clear, brief and precise technical and mathematical accounts for\\nthe relation between nominal and structural OO type systems. NOOP, thus,\\nprovides a firmer semantic foundation for analyzing and progressing\\nnominally-typed OO programming languages.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/1801.06793v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 3:\n",
            "{\n",
            "  \"title\": \"Scan Correlation -- Revealing distributed scan campaigns\",\n",
            "  \"authors\": [\n",
            "    \"Steffen Haas\",\n",
            "    \"Florian Wilkens\",\n",
            "    \"Mathias Fischer\"\n",
            "  ],\n",
            "  \"abstract\": \"  Public networks are exposed to port scans from the Internet. Attackers search\\nfor vulnerable services they can exploit. In large scan campaigns, attackers\\noften utilize different machines to perform distributed scans, which impedes\\ntheir detection and might also camouflage the actual goal of the scanning\\ncampaign. In this paper, we present a correlation algorithm to detect scans,\\nidentify potential relations among them, and reassemble them to larger\\ncampaigns. We evaluate our approach on real-world Internet traffic and our\\nresults indicate that it can summarize and characterize standalone and\\ndistributed scan campaigns based on their tools and intention.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/2003.05188v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 4:\n",
            "{\n",
            "  \"title\": \"Semantics-based Privacy by Design for Internet of Things Applications\",\n",
            "  \"authors\": [\n",
            "    \"Lamya Alkhariji\",\n",
            "    \"Suparna De\",\n",
            "    \"Omer Rana\",\n",
            "    \"Charith Perera\"\n",
            "  ],\n",
            "  \"abstract\": \"  As Internet of Things (IoT) technologies become more widespread in everyday\\nlife, privacy issues are becoming more prominent. The aim of this research is\\nto develop a personal assistant that can answer software engineers' questions\\nabout Privacy by Design (PbD) practices during the design phase of IoT system\\ndevelopment. Semantic web technologies are used to model the knowledge\\nunderlying PbD measurements, their intersections with privacy patterns, IoT\\nsystem requirements and the privacy patterns that should be applied across IoT\\nsystems. This is achieved through the development of the PARROT ontology,\\ndeveloped through a set of representative IoT use cases relevant for software\\ndevelopers. This was supported by gathering Competency Questions (CQs) through\\na series of workshops, resulting in 81 curated CQs. These CQs were then\\nrecorded as SPARQL queries, and the developed ontology was evaluated using the\\nCommon Pitfalls model with the help of the Prot\\\\'eg\\\\'e HermiT Reasoner and the\\nOntology Pitfall Scanner (OOPS!), as well as evaluation by external experts.\\nThe ontology was assessed within a user study that identified that the PARROT\\nontology can answer up to 58\\\\% of privacy-related questions from software\\nengineers.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/2210.01778v1\"\n",
            "}\n",
            "----------------------------------------\n",
            "Article 5:\n",
            "{\n",
            "  \"title\": \"Identifying and characterizing ZMap scans: a cryptanalytic approach\",\n",
            "  \"authors\": [\n",
            "    \"Johan Mazel\",\n",
            "    \"R\\u00e9mi Strullu\"\n",
            "  ],\n",
            "  \"abstract\": \"  Network scanning tools play a major role in Internet security. They are used\\nby both network security researchers and malicious actors to identify\\nvulnerable machines exposed on the Internet. ZMap is one of the most common\\nprobing tools for high-speed Internet-wide scanning. We present novel\\nidentification methods based on the IPv4 iteration process of ZMap. These\\nmethods can be used to identify ZMap scans with a small number of addresses\\nextracted from the scan. We conduct an experimental evaluation of these\\ndetection methods on synthetic, network telescope, and backbone traffic. We\\nmanage to identify 28.5% of the ZMap scans in real-world traffic. We then\\nperform an in-depth characterization of these scans regarding, for example,\\ntargeted prefix and probing speed.\\n\",\n",
            "  \"url\": \"http://arxiv.org/abs/1908.04193v2\"\n",
            "}\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "# --- STEP 1: Read input document ---\n",
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "# --- STEP 2: Extract keyword-based query ---\n",
        "def generate_query(text, num_keywords=5):\n",
        "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    words = text.split()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [w for w in words if w not in stop_words]\n",
        "    most_common = Counter(filtered_words).most_common(num_keywords)\n",
        "    keywords = [word for word, count in most_common]\n",
        "    return \" \".join(keywords)\n",
        "\n",
        "# --- STEP 3: Fetch articles from arXiv ---\n",
        "def fetch_arxiv_articles(query, max_results=5):\n",
        "    search_url = f'http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}'\n",
        "    response = requests.get(search_url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, 'xml')\n",
        "    articles = []\n",
        "    for entry in soup.find_all('entry'):\n",
        "        title = entry.title.text\n",
        "        authors = [author.find('name').text for author in entry.find_all('author')]\n",
        "        abstract = entry.summary.text\n",
        "        url = entry.id.text\n",
        "        articles.append({\n",
        "            'title': title,\n",
        "            'authors': authors,\n",
        "            'abstract': abstract,\n",
        "            'url': url\n",
        "        })\n",
        "    return articles\n",
        "\n",
        "# --- MAIN ---\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"user_input.txt\"  # Replace with your file path\n",
        "    doc_text = read_text_file(file_path)\n",
        "\n",
        "    generated_query = generate_query(doc_text)\n",
        "    print(f\" Generated Query: {generated_query}\")\n",
        "\n",
        "    print(\"\\n Fetching Similar Articles from arXiv...\\n\")\n",
        "    arxiv_results = fetch_arxiv_articles(generated_query)\n",
        "\n",
        "    # Save the articles data as a JSON file\n",
        "    with open('/content/web_dataset.json', 'w') as f:\n",
        "        json.dump(arxiv_results, f, indent=4)  # Use indent for better formatting\n",
        "\n",
        "    for idx, article in enumerate(arxiv_results, 1):\n",
        "        print(f\"Article {idx}:\")\n",
        "        print(json.dumps(article, indent=2))\n",
        "        print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNC_6tuyAkl_",
        "outputId": "9b771868-41c8-46c3-bc6c-a8a2a69c86e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
            "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cosine_similarity   |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
            "|Identifying and characterizing ZMap scans: a cryptanalytic approach.   Network scanning tools play a major role in Internet security. They are used\\nby both network security researchers and malicious actors to identify\\nvulnerable machines exposed on the Internet. ZMap is one of the most common\\nprobing tools for high-speed Internet-wide scanning. We present novel\\nidentification methods based on the IPv4 iteration process of ZMap. These\\nmethods can be used to identify ZMap scans with a small number of addresses\\nextracted from the scan. We conduct an experimental evaluation of these\\ndetection methods on synthetic, network telescope, and backbone traffic. We\\nmanage to identify 28.5% of the ZMap scans in real-world traffic. We then\\nperform an in-depth characterization of these scans regarding, for example,\\ntargeted prefix and probing speed.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |0.018931224597556223|\n",
            "|Oops!...I think I scanned a malware.   This article presents a proof-of-concept illustrating the feasibility of\\ncreating a covert channel between a C\\&C server and a malware installed in an\\norganization by exploiting an organization's scanner and using it as a means of\\ninteraction. We take advantage of the light sensitivity of a flatbed scanner,\\nusing a light source to infiltrate data to an organization. We present an\\nimplementation of the method for different purposes (even to trigger a\\nransomware attack) in various experimental setups using: (1) a laser connected\\nto a stand (2) a laser carried by a drone, and (3) a hijacked smart bulb within\\nthe targeted organization from a passing car. In our experiments we were able\\nto infiltrate data using different types of light sources (including infrared\\nlight), from a distance of up to 900 meters away from the scanner. We discuss\\npotential counter measures to prevent the attack.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |0.015203264695122034|\n",
            "|Scan Correlation -- Revealing distributed scan campaigns.   Public networks are exposed to port scans from the Internet. Attackers search\\nfor vulnerable services they can exploit. In large scan campaigns, attackers\\noften utilize different machines to perform distributed scans, which impedes\\ntheir detection and might also camouflage the actual goal of the scanning\\ncampaign. In this paper, we present a correlation algorithm to detect scans,\\nidentify potential relations among them, and reassemble them to larger\\ncampaigns. We evaluate our approach on real-world Internet traffic and our\\nresults indicate that it can summarize and characterize standalone and\\ndistributed scan campaigns based on their tools and intention.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |0.014730508715817036|\n",
            "|Semantics-based Privacy by Design for Internet of Things Applications.   As Internet of Things (IoT) technologies become more widespread in everyday\\nlife, privacy issues are becoming more prominent. The aim of this research is\\nto develop a personal assistant that can answer software engineers' questions\\nabout Privacy by Design (PbD) practices during the design phase of IoT system\\ndevelopment. Semantic web technologies are used to model the knowledge\\nunderlying PbD measurements, their intersections with privacy patterns, IoT\\nsystem requirements and the privacy patterns that should be applied across IoT\\nsystems. This is achieved through the development of the PARROT ontology,\\ndeveloped through a set of representative IoT use cases relevant for software\\ndevelopers. This was supported by gathering Competency Questions (CQs) through\\na series of workshops, resulting in 81 curated CQs. These CQs were then\\nrecorded as SPARQL queries, and the developed ontology was evaluated using the\\nCommon Pitfalls model with the help of the Prot\\'eg\\'e HermiT Reasoner and the\\nOntology Pitfall Scanner (OOPS!), as well as evaluation by external experts.\\nThe ontology was assessed within a user study that identified that the PARROT\\nontology can answer up to 58\\% of privacy-related questions from software\\nengineers.\\n                                                                                                                                                                                                                                                                                                                                                                    |0.006938609660139257|\n",
            "|NOOP: A Domain-Theoretic Model of Nominally-Typed OOP.   The majority of industrial-strength object-oriented (OO) software is written\\nusing nominally-typed OO programming languages. Extant domain-theoretic models\\nof OOP developed to analyze OO type systems miss, however, a crucial feature of\\nthese mainstream OO languages: nominality. This paper presents the construction\\nof NOOP as the first domain-theoretic model of OOP that includes full\\nclass/type names information found in nominally-typed OOP. Inclusion of nominal\\ninformation in objects of NOOP and asserting that type inheritance in\\nstatically-typed OO programming languages is an inherently nominal notion allow\\nreadily proving that type inheritance and subtyping are completely identified\\nin these languages. This conclusion is in full agreement with intuitions of\\ndevelopers and language designers of these OO languages, and contrary to the\\nbelief that \"inheritance is not subtyping,\" which came from assuming\\nnon-nominal (a.k.a., structural) models of OOP.\\n  To motivate the construction of NOOP, this paper briefly presents the\\nbenefits of nominal-typing to mainstream OO developers and OO language\\ndesigners, as compared to structural-typing. After presenting NOOP, the paper\\nfurther briefly compares NOOP to the most widely known domain-theoretic models\\nof OOP. Leveraging the development of NOOP, the comparisons presented in this\\npaper provide clear, brief and precise technical and mathematical accounts for\\nthe relation between nominal and structural OO type systems. NOOP, thus,\\nprovides a firmer semantic foundation for analyzing and progressing\\nnominally-typed OO programming languages.\\n|0.005062546534799927|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import math\n",
        "\n",
        "# Sample assumption: user_text already exists from PDF preprocessing\n",
        "# If not, set user_text = \"Your extracted document text\"\n",
        "\n",
        "# Step 2.1: Prepare the web data from arXiv (if already fetched)\n",
        "# If you have arxiv_results from earlier:\n",
        "arxiv_df = spark.createDataFrame(\n",
        "    [Row(text=article[\"title\"] + \". \" + article[\"abstract\"], source=\"arxiv\") for article in arxiv_results]\n",
        ")\n",
        "\n",
        "# Step 2.2: Convert user text into a DataFrame\n",
        "user_df = spark.createDataFrame([Row(text=pdf_text, source=\"user_input\")])\n",
        "\n",
        "# Step 2.3: Combine both into combined_df\n",
        "combined_df = user_df.union(arxiv_df)\n",
        "\n",
        "# Step 2.4: Tokenization\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "words_data = tokenizer.transform(combined_df)\n",
        "\n",
        "# Step 2.5: TF and IDF\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "featurized_data = hashingTF.transform(words_data)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "idf_model = idf.fit(featurized_data)\n",
        "rescaled_data = idf_model.transform(featurized_data)\n",
        "\n",
        "# Step 2.6: Normalize vectors for cosine similarity\n",
        "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\")\n",
        "normalized_data = normalizer.transform(rescaled_data)\n",
        "\n",
        "# Step 2.7: Compute Cosine Similarity of user_input with each arxiv result\n",
        "user_vector = normalized_data.filter(normalized_data.source == \"user_input\").select(\"normFeatures\").first()[\"normFeatures\"]\n",
        "\n",
        "# UDF to compute cosine similarity\n",
        "def cosine_sim(vec):\n",
        "    return float(vec.dot(user_vector))\n",
        "\n",
        "cosine_sim_udf = udf(cosine_sim, DoubleType())\n",
        "scored_df = normalized_data.withColumn(\"cosine_similarity\", cosine_sim_udf(\"normFeatures\"))\n",
        "\n",
        "# Step 2.8: Show sorted results (excluding self-comparison)\n",
        "scored_df.filter(scored_df.source != \"user_input\") \\\n",
        "    .select(\"text\", \"cosine_similarity\") \\\n",
        "    .orderBy(\"cosine_similarity\", ascending=False) \\\n",
        "    .show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrJQhmVRB1jU",
        "outputId": "71c3b8ba-c823-46a9-ae83-404717b745a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2iIqWUrDDzp",
        "outputId": "bbf7a15e-0beb-4f72-e6f1-26035bfa0acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spark-3.4.1-bin-hadoop3/\n",
            "spark-3.4.1-bin-hadoop3/R/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/sparkr.zip\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.4.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.4.1-bin-hadoop3/sbin/\n",
            "spark-3.4.1-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-connect-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-connect-server.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.4.1-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.4.1-bin-hadoop3/python/\n",
            "spark-3.4.1-bin-hadoop3/python/dist/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/test_pytorch_training_file.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.4.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.4.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.4.1-bin-hadoop3/python/setup.cfg\n",
            "spark-3.4.1-bin-hadoop3/python/run-tests.py\n",
            "spark-3.4.1-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.4.1-bin-hadoop3/python/docs/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/udf.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/protobuf.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/resampling.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.errors.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_upgrade.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_connect.ipynb\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.4.1-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
            "spark-3.4.1-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.4.1-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.4.1-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.4.1-bin-hadoop3/python/README.md\n",
            "spark-3.4.1-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.4.1-bin-hadoop3/python/.gitignore\n",
            "spark-3.4.1-bin-hadoop3/python/.coveragerc\n",
            "spark-3.4.1-bin-hadoop3/python/mypy.ini\n",
            "spark-3.4.1-bin-hadoop3/python/setup.py\n",
            "spark-3.4.1-bin-hadoop3/python/run-tests\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/distributor.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/torch_run_process_wrapper.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_log_communication.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_distributor.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/log_communication.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_model_cache.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/model_cache.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/test_errors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/connect.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/error_classes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/errors/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_stage_sched.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rddsampler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_memory_profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/testing/connectutils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_scalars.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_resample.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_slow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby_slow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_generic_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ewm.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_slow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/resample.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/scalars.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/resample.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/correlation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/supported_api_gen.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_sqlmetrics.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_errors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_scalar.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_grouped_agg.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_serde.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_errors.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_datasources.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_cogrouped_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_plan.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_function.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_basic.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_client.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_python_udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/state.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/query.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/listener.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2_grpc.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/window.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/session.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/plan.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/group.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/expressions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/conversion.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/client.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/_typing.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.4.1-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.4.1-bin-hadoop3/python/lib/\n",
            "spark-3.4.1-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.4.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip\n",
            "spark-3.4.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.4.1-bin-hadoop3/bin/\n",
            "spark-3.4.1-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/sparkR\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-submit\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-sql\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-shell\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-connect-shell\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/spark-class\n",
            "spark-3.4.1-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/run-example\n",
            "spark-3.4.1-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/pyspark\n",
            "spark-3.4.1-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.4.1-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/find-spark-home\n",
            "spark-3.4.1-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.4.1-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.4.1-bin-hadoop3/bin/beeline\n",
            "spark-3.4.1-bin-hadoop3/README.md\n",
            "spark-3.4.1-bin-hadoop3/conf/\n",
            "spark-3.4.1-bin-hadoop3/conf/workers.template\n",
            "spark-3.4.1-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.4.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.4.1-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.4.1-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.4.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.4.1-bin-hadoop3/data/\n",
            "spark-3.4.1-bin-hadoop3/data/streaming/\n",
            "spark-3.4.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/als/\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.4.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.4.1-bin-hadoop3/data/graphx/\n",
            "spark-3.4.1-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.4.1-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.4.1-bin-hadoop3/NOTICE\n",
            "spark-3.4.1-bin-hadoop3/licenses/\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.4.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.4.1-bin-hadoop3/LICENSE\n",
            "spark-3.4.1-bin-hadoop3/examples/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.4.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.4.1-bin-hadoop3/examples/jars/\n",
            "spark-3.4.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.4.1-bin-hadoop3/yarn/\n",
            "spark-3.4.1-bin-hadoop3/yarn/spark-3.4.1-yarn-shuffle.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/\n",
            "spark-3.4.1-bin-hadoop3/jars/rocksdbjni-7.9.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/py4j-0.10.9.7.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/pickle-1.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-jackson-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-hadoop-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-format-structures-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-encoding-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-common-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/parquet-column-1.12.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/orc-shims-1.8.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/orc-mapreduce-1.8.4-shaded-protobuf.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/orc-core-1.8.4-shaded-protobuf.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/okio-1.15.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/objenesis-3.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.87.Final-osx-x86_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.87.Final-osx-aarch_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.87.Final-linux-x86_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.87.Final-linux-aarch_64.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-transport-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-resolver-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-handler-proxy-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-handler-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-common-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-socks-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-http2-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-http-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-codec-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-buffer-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/netty-all-4.1.87.Final.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-jvm-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-json-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-jmx-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-graphite-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/metrics-core-4.2.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-slf4j2-impl-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-core-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-api-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/log4j-1.2-api-2.19.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/lapack-3.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-storageclass-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-scheduling-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-rbac-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-policy-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-node-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-networking-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-metrics-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-gatewayapi-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-extensions-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-events-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-discovery-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-core-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-coordination-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-common-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-certificates-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-batch-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-autoscaling-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-apps-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-apiextensions-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-httpclient-okhttp-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-client-api-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kubernetes-client-6.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jul-to-slf4j-2.0.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/joda-time-2.12.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-server-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-hk2-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-container-servlet-core-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-container-servlet-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-common-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jersey-client-2.36.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jcl-over-slf4j-2.0.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/janino-3.1.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-databind-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-core-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/jackson-annotations-2.14.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/ivy-2.5.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/httpcore-4.4.16.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/httpclient-4.5.14.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-storage-api-2.8.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-service-rpc-3.1.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/hadoop-client-api-3.3.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/compress-lzf-1.1.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-text-1.10.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-io-2.11.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-compress-1.22.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-compiler-3.1.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-codec-1.15.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/breeze_2.12-2.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/breeze-macros_2.12-2.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/blas-3.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/avro-mapred-1.11.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/avro-ipc-1.11.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/avro-1.11.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-vector-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-memory-netty-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-memory-core-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arrow-format-11.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/arpack-3.0.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/antlr4-runtime-4.9.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/aircompressor-0.21.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/RoaringBitmap-0.9.38.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zstd-jni-1.5.2-5.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zookeeper-jute-3.6.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zookeeper-3.6.3.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/xz-1.9.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/xbean-asm9-shaded-4.22.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/tink-1.7.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/threeten-extra-1.7.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-yarn_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-unsafe_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-tags_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-streaming_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-sql_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-sketch_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-repl_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-network-common_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-mllib_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-mesos_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-launcher_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-kvstore_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-hive_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-graphx_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-core_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/spark-catalyst_2.12-3.4.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/snappy-java-1.1.10.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/snakeyaml-1.33.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/slf4j-api-2.0.6.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/shims-0.9.38.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-xml_2.12-2.1.0.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-reflect-2.12.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-parser-combinators_2.12-2.1.1.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-library-2.12.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-compiler-2.12.17.jar\n",
            "spark-3.4.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.7.0.jar\n",
            "spark-3.4.1-bin-hadoop3/RELEASE\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m710.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc268f86-6589-49e2-b2a6-b4ae94d914f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc268f86-6589-49e2-b2a6-b4ae94d914f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# STEP 0: INSTALLS & SETUP\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar -xvzf spark-3.4.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark spark-nlp nltk beautifulsoup4 requests sentence-transformers\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "import requests, string, json\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.functions import col, lit\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "import pandas as pd\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PlagiarismDetectionPipeline\").getOrCreate()\n",
        "\n",
        "# STEP 1: USER FILE UPLOAD\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file_path = list(uploaded.keys())[0]\n",
        "\n",
        "# STEP 2: READ TEXT FILE + EXTRACT KEYWORDS\n",
        "def read_text_file(fp):\n",
        "    with open(fp, 'r', encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "def generate_query(text, num_keywords=5):\n",
        "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    words = text.split()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered = [w for w in words if w not in stop_words]\n",
        "    keywords = [word for word, count in Counter(filtered).most_common(num_keywords)]\n",
        "    return \" \".join(keywords)\n",
        "\n",
        "user_text = read_text_file(file_path)\n",
        "query = generate_query(user_text)\n",
        "\n",
        "# STEP 3: FETCH SIMILAR ARTICLES FROM ARXIV\n",
        "def fetch_arxiv_articles(query, max_results=5):\n",
        "    search_url = f\"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}\"\n",
        "    response = requests.get(search_url)\n",
        "    soup = BeautifulSoup(response.content, 'xml')\n",
        "    articles = []\n",
        "    for entry in soup.find_all('entry'):\n",
        "        title = entry.title.text\n",
        "        authors = [author.find('name').text for author in entry.find_all('author')]\n",
        "        abstract = entry.summary.text\n",
        "        url = entry.id.text\n",
        "        articles.append(f\"{title}. {abstract}\")\n",
        "    return articles\n",
        "\n",
        "arxiv_articles = fetch_arxiv_articles(query)\n",
        "all_docs = [user_text] + arxiv_articles\n",
        "\n",
        "# STEP 4: LOAD INTO SPARK\n",
        "rows = [Row(text=doc) for doc in all_docs]\n",
        "df = spark.createDataFrame(rows)\n",
        "\n",
        "# STEP 5: TOKENIZATION + TF-IDF\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "words_data = tokenizer.transform(df)\n",
        "hashing_tf = HashingTF(inputCol=\"words\", outputCol=\"raw_features\")\n",
        "featurized_data = hashing_tf.transform(words_data)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "idf_model = idf.fit(featurized_data)\n",
        "tfidf_data = idf_model.transform(featurized_data)\n",
        "\n",
        "# STEP 6: COSINE SIMILARITY + SENTENCE MATCHING\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "user_sentences = sent_tokenize(user_text)\n",
        "article_sentences = []\n",
        "article_ids = []\n",
        "\n",
        "for i, article in enumerate(arxiv_articles):\n",
        "    sents = sent_tokenize(article)\n",
        "    article_sentences.extend(sents)\n",
        "    article_ids.extend([i + 1] * len(sents))  # i+1 because 0 is the user\n",
        "\n",
        "user_embeddings = model.encode(user_sentences, convert_to_tensor=True)\n",
        "article_embeddings = model.encode(article_sentences, convert_to_tensor=True)\n",
        "\n",
        "cos_scores = util.cos_sim(user_embeddings, article_embeddings)\n",
        "\n",
        "similar_pairs = []\n",
        "for i in range(len(user_sentences)):\n",
        "    for j in range(len(article_sentences)):\n",
        "        score = cos_scores[i][j].item()\n",
        "        if score > 0.75:\n",
        "            similar_pairs.append({\n",
        "                \"user_sentence\": user_sentences[i],\n",
        "                \"matched_sentence\": article_sentences[j],\n",
        "                \"article_id\": article_ids[j],\n",
        "                \"similarity_score\": score\n",
        "            })\n",
        "\n",
        "# STEP 7: DISPLAY TOP MATCHES\n",
        "if similar_pairs:\n",
        "    df_result = pd.DataFrame(similar_pairs).sort_values(by=\"similarity_score\", ascending=False)\n",
        "    print(\"\\n Top Similar Sentences Found:\")\n",
        "    display(df_result.head(10))\n",
        "else:\n",
        "    print(\" No significant plagiarism detected.\")\n",
        "\n",
        "# OPTIONAL STEP 8: SAVE TO JSON REPORT\n",
        "with open(\"/content/plagiarism_report.json\", \"w\") as f:\n",
        "    json.dump(similar_pairs, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1nQB6XZExW7",
        "outputId": "d3c48d8a-c099-468c-c06d-2dd1ae930b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n",
            "  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n",
            "  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libudev1 libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n",
            "  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n",
            "  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wpasupplicant\n",
            "Suggested packages:\n",
            "  avahi-autoipd gnome-shell | notification-daemon avahi-autoipd | zeroconf\n",
            "  qt5-image-formats-plugins qtwayland5 qt5-qmltooling-plugins comgt wvdial\n",
            "  wpagui libengine-pkcs11-openssl\n",
            "The following NEW packages will be installed:\n",
            "  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n",
            "  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n",
            "  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n",
            "  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n",
            "  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wkhtmltopdf\n",
            "  wpasupplicant\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 67 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 35.5 MB of archives.\n",
            "After this operation, 141 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-core7 amd64 0.8-5ubuntu5.2 [90.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdaemon0 amd64 0.14-7.1ubuntu3 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 avahi-daemon amd64 0.8-5ubuntu5.2 [69.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.15 [76.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5positioning5 amd64 5.15.3+dfsg-3 [223 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5printsupport5 amd64 5.15.3+dfsg-2ubuntu0.2 [214 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qml5 amd64 5.15.3+dfsg-1 [1,472 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qmlmodels5 amd64 5.15.3+dfsg-1 [205 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quick5 amd64 5.15.3+dfsg-1 [1,748 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5sensors5 amd64 5.15.3-1 [123 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webchannel5 amd64 5.15.3-1 [62.9 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webkit5 amd64 5.212.0~alpha4-15ubuntu1 [12.8 MB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.15 [1,557 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-glib1 amd64 0.8-5ubuntu5.2 [8,296 B]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmm-glib0 amd64 1.20.0-1~ubuntu22.04.4 [262 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.2 [4,192 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.2 [287 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 geoclue-2.0 amd64 2.5.7-3ubuntu3 [111 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 iio-sensor-proxy amd64 3.3-0ubuntu6 [34.4 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-glib4 amd64 1.28.0-1~ubuntu20.04.2 [192 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-proxy amd64 1.28.0-1~ubuntu20.04.2 [6,160 B]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnss-mdns amd64 0.15.1-1ubuntu1 [27.0 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-glib5 amd64 1.32.0-1ubuntu0.22.04.1 [772 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-proxy amd64 1.32.0-1ubuntu0.22.04.1 [6,072 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 modemmanager amd64 1.20.0-1~ubuntu22.04.4 [1,094 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 wpasupplicant amd64 2:2.10-6ubuntu2.2 [1,482 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch-data all 20191128-4 [33.2 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch amd64 2.6.1-3ubuntu2 [46.0 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 wkhtmltopdf amd64 0.12.6-2 [173 kB]\n",
            "Fetched 35.5 MB in 3s (12.0 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libavahi-core7:amd64.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libavahi-core7_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libdaemon0:amd64.\n",
            "Preparing to unpack .../1-libdaemon0_0.14-7.1ubuntu3_amd64.deb ...\n",
            "Unpacking libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Selecting previously unselected package avahi-daemon.\n",
            "Preparing to unpack .../2-avahi-daemon_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "Preparing to unpack .../3-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../4-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../5-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Preparing to unpack .../6-libudev1_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.15) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "(Reading database ... 126384 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../01-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../02-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../03-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../04-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../05-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../06-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../07-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../08-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../09-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../10-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../11-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../12-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../13-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../14-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../15-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../16-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../17-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../18-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../19-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libhyphen0:amd64.\n",
            "Preparing to unpack .../20-libhyphen0_2.8.8-7build2_amd64.deb ...\n",
            "Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Selecting previously unselected package libqt5positioning5:amd64.\n",
            "Preparing to unpack .../21-libqt5positioning5_5.15.3+dfsg-3_amd64.deb ...\n",
            "Unpacking libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Selecting previously unselected package libqt5printsupport5:amd64.\n",
            "Preparing to unpack .../22-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5qml5:amd64.\n",
            "Preparing to unpack .../23-libqt5qml5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5qmlmodels5:amd64.\n",
            "Preparing to unpack .../24-libqt5qmlmodels5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5quick5:amd64.\n",
            "Preparing to unpack .../25-libqt5quick5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5sensors5:amd64.\n",
            "Preparing to unpack .../26-libqt5sensors5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libqt5webchannel5:amd64.\n",
            "Preparing to unpack .../27-libqt5webchannel5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../28-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package libqt5webkit5:amd64.\n",
            "Preparing to unpack .../29-libqt5webkit5_5.212.0~alpha4-15ubuntu1_amd64.deb ...\n",
            "Unpacking libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../30-udev_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libavahi-glib1:amd64.\n",
            "Preparing to unpack .../31-libavahi-glib1_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-common.\n",
            "Preparing to unpack .../32-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\n",
            "Unpacking libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-0:amd64.\n",
            "Preparing to unpack .../33-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\n",
            "Unpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libmm-glib0:amd64.\n",
            "Preparing to unpack .../34-libmm-glib0_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../35-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libproxy1v5:amd64.\n",
            "Preparing to unpack .../36-libproxy1v5_0.4.17-2_amd64.deb ...\n",
            "Unpacking libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Selecting previously unselected package glib-networking-common.\n",
            "Preparing to unpack .../37-glib-networking-common_2.72.0-1_all.deb ...\n",
            "Unpacking glib-networking-common (2.72.0-1) ...\n",
            "Selecting previously unselected package glib-networking-services.\n",
            "Preparing to unpack .../38-glib-networking-services_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking-services (2.72.0-1) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../39-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../40-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package glib-networking:amd64.\n",
            "Preparing to unpack .../41-glib-networking_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking:amd64 (2.72.0-1) ...\n",
            "Selecting previously unselected package libsoup2.4-common.\n",
            "Preparing to unpack .../42-libsoup2.4-common_2.74.2-3ubuntu0.2_all.deb ...\n",
            "Unpacking libsoup2.4-common (2.74.2-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libsoup2.4-1:amd64.\n",
            "Preparing to unpack .../43-libsoup2.4-1_2.74.2-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.2) ...\n",
            "Selecting previously unselected package geoclue-2.0.\n",
            "Preparing to unpack .../44-geoclue-2.0_2.5.7-3ubuntu3_amd64.deb ...\n",
            "Unpacking geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Selecting previously unselected package iio-sensor-proxy.\n",
            "Preparing to unpack .../45-iio-sensor-proxy_3.3-0ubuntu6_amd64.deb ...\n",
            "Unpacking iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Selecting previously unselected package libmbim-glib4:amd64.\n",
            "Preparing to unpack .../46-libmbim-glib4_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libmbim-proxy.\n",
            "Preparing to unpack .../47-libmbim-proxy_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libnl-genl-3-200:amd64.\n",
            "Preparing to unpack .../48-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...\n",
            "Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Selecting previously unselected package libnss-mdns:amd64.\n",
            "Preparing to unpack .../49-libnss-mdns_0.15.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libqmi-glib5:amd64.\n",
            "Preparing to unpack .../50-libqmi-glib5_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libqmi-proxy.\n",
            "Preparing to unpack .../51-libqmi-proxy_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../52-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package modemmanager.\n",
            "Preparing to unpack .../53-modemmanager_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../54-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../55-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../56-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package wpasupplicant.\n",
            "Preparing to unpack .../57-wpasupplicant_2%3a2.10-6ubuntu2.2_amd64.deb ...\n",
            "Unpacking wpasupplicant (2:2.10-6ubuntu2.2) ...\n",
            "Selecting previously unselected package usb-modeswitch-data.\n",
            "Preparing to unpack .../58-usb-modeswitch-data_20191128-4_all.deb ...\n",
            "Unpacking usb-modeswitch-data (20191128-4) ...\n",
            "Selecting previously unselected package usb-modeswitch.\n",
            "Preparing to unpack .../59-usb-modeswitch_2.6.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Selecting previously unselected package wkhtmltopdf.\n",
            "Preparing to unpack .../60-wkhtmltopdf_0.12.6-2_amd64.deb ...\n",
            "Unpacking wkhtmltopdf (0.12.6-2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service  /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up usb-modeswitch-data (20191128-4) ...\n",
            "Setting up udev (249.11-0ubuntu3.15) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up libsoup2.4-common (2.74.2-3ubuntu0.2) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Setting up usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Setting up glib-networking-common (2.72.0-1) ...\n",
            "Setting up libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Setting up libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Setting up libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "First installation detected...\n",
            "Checking NSS setup...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up glib-networking-services (2.72.0-1) ...\n",
            "Setting up iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Setting up libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up wpasupplicant (2:2.10-6ubuntu2.2) ...\n",
            "Created symlink /etc/systemd/system/dbus-fi.w1.wpa_supplicant1.service  /lib/systemd/system/wpa_supplicant.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/wpa_supplicant.service  /lib/systemd/system/wpa_supplicant.service.\n",
            "Setting up libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of force-reload.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.Avahi.service  /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/avahi-daemon.service  /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/avahi-daemon.socket  /lib/systemd/system/avahi-daemon.socket.\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Setting up modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.ModemManager1.service  /lib/systemd/system/ModemManager.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ModemManager.service  /lib/systemd/system/ModemManager.service.\n",
            "Setting up wkhtmltopdf (0.12.6-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Setting up glib-networking:amd64 (2.72.0-1) ...\n",
            "Setting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.2) ...\n",
            "Setting up geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Collecting pdfkit\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: pdfkit\n",
            "Successfully installed pdfkit-1.0.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.1\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies for PDF generation\n",
        "!apt-get install -y wkhtmltopdf\n",
        "!pip install pdfkit\n",
        "\n",
        "# Install Gradio for Web UI\n",
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "bp2EAB9UFwv9",
        "outputId": "b0110aa2-f589-46e5-eb68-8cd42d345804"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-704c8b54-d423-4166-93ed-c670871927b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-704c8b54-d423-4166-93ed-c670871927b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving user_input.txt to user_input (1).txt\n",
            "Document successfully uploaded and read!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the document\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the document content\n",
        "file_path = list(uploaded.keys())[0]  # Get the filename\n",
        "with open(file_path, 'r') as file:\n",
        "    user_document = file.read()\n",
        "\n",
        "print(\"Document successfully uploaded and read!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "JCgX8uQxF0Vj",
        "outputId": "977930d5-8717-4cb2-ec42-1a5314995863"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e2b5a4342c66>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprocessed_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_document\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e2b5a4342c66>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Tokenize and convert to lowercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mfiltered_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalnum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     return [\n\u001b[1;32m    144\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Download the missing Punkt model\n",
        "\n",
        "# Tokenize and remove stopwords\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
        "    filtered_tokens = [word for word in word_tokens if word.isalnum() and word not in stop_words]\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "processed_document = preprocess_text(user_document)\n",
        "print(\"Preprocessing completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CWrA-MtF37U"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Fetch articles from ArXiv based on a query\n",
        "def fetch_arxiv_articles(query, max_results=5):\n",
        "    search_url = f'http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}'\n",
        "    response = requests.get(search_url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, 'xml')\n",
        "    articles = []\n",
        "    for entry in soup.find_all('entry'):\n",
        "        title = entry.title.text\n",
        "        authors = [author.find('name').text for author in entry.find_all('author')]\n",
        "        abstract = entry.summary.text\n",
        "        url = entry.id.text\n",
        "        articles.append({'title': title, 'authors': authors, 'abstract': abstract, 'url': url})\n",
        "    return articles\n",
        "\n",
        "# Generate query from the document text\n",
        "query = ' '.join(processed_document.split()[:5])  # First 5 words of the document as the query\n",
        "articles = fetch_arxiv_articles(query)\n",
        "print(f\"Found {len(articles)} articles!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRPG3br2F5rp"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize sentence transformer model (BERT-based)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Encode the user's document and fetched articles\n",
        "doc_embedding = model.encode([processed_document])\n",
        "article_embeddings = model.encode([article['abstract'] for article in articles])\n",
        "\n",
        "# Compute cosine similarity between document and articles\n",
        "similarity_scores = cosine_similarity(doc_embedding, article_embeddings)\n",
        "\n",
        "# Show the similarity scores\n",
        "for idx, score in enumerate(similarity_scores[0]):\n",
        "    print(f\"Article {idx+1}: Similarity Score = {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMR2ePBSGLsg"
      },
      "outputs": [],
      "source": [
        "!pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHH1rsk5GrPD"
      },
      "outputs": [],
      "source": [
        "!pip install reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUbjKOOAGuZS"
      },
      "outputs": [],
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "import datetime\n",
        "\n",
        "# Generate report using reportlab\n",
        "def generate_report_with_reportlab(similarity_scores, articles, user_document):\n",
        "    pdf_output_path = \"/content/plagiarism_report_reportlab.pdf\"\n",
        "\n",
        "    c = canvas.Canvas(pdf_output_path, pagesize=letter)\n",
        "\n",
        "    # Title\n",
        "    c.setFont(\"Helvetica-Bold\", 16)\n",
        "    c.drawString(200, 750, \"Plagiarism Detection Report\")\n",
        "\n",
        "    # Date\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(200, 730, f\"Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    # User document preview\n",
        "    c.drawString(50, 700, \"User Document Preview:\")\n",
        "    c.setFont(\"Helvetica\", 10)\n",
        "    c.drawString(50, 680, f\"{user_document[:500]}...\")  # Preview first 500 characters\n",
        "\n",
        "    # Articles and similarity results\n",
        "    y_position = 650\n",
        "    c.setFont(\"Helvetica-Bold\", 12)\n",
        "    for idx, score in enumerate(similarity_scores[0]):\n",
        "        c.drawString(50, y_position, f\"Article {idx+1}: Similarity Score = {score:.4f}\")\n",
        "        y_position -= 20\n",
        "        c.setFont(\"Helvetica\", 10)\n",
        "        c.drawString(50, y_position, f\"Title: {articles[idx]['title']}\")\n",
        "        y_position -= 20\n",
        "        c.drawString(50, y_position, f\"Abstract: {articles[idx]['abstract']}\")\n",
        "        y_position -= 20\n",
        "        c.drawString(50, y_position, f\"URL: {articles[idx]['url']}\")\n",
        "        y_position -= 40\n",
        "\n",
        "    c.save()\n",
        "    return pdf_output_path\n",
        "\n",
        "# Generate the report with reportlab\n",
        "pdf_report_path_rl = generate_report_with_reportlab(similarity_scores, articles, user_document)\n",
        "print(f\"Plagiarism report saved to: {pdf_report_path_rl}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX9QeXHhHn9H"
      },
      "outputs": [],
      "source": [
        "pdf_report_path_rl = generate_report_with_reportlab(similarity_scores, articles, user_document)\n",
        "print(f\"Plagiarism report saved to: {pdf_report_path_rl}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3QH4DmEHqYq"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(pdf_report_path_rl)  # For ReportLab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1akxNWJRH_Le"
      },
      "outputs": [],
      "source": [
        "!pip install Flask Flask-Uploads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v92u2VBiIjwM"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvcDhpZ_I68w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}